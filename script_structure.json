[
  {
    "title": "Документация по разработке: Система автоматической проверки возрастного рейтинга сценария",
    "level": 1,
    "content": [],
    "children": [
      {
        "title": "Обзор проекта",
        "level": 2,
        "content": [
          "При создании киносценариев для широкого проката чрезвычайно важно придерживаться требуемого возрастного рейтинга. Согласно Федеральному закону № 436-ФЗ «О защите детей от информации, причиняющей вред их здоровью и развитию», вся информационная продукция (в том числе фильмы и сценарии) должна классифицироваться по пяти возрастным категориям: 0+, 6+, 12+, 16+, 18+. Нарушение требований рейтинга может привести к ограничению показа фильма в кинотеатрах, на ТВ и стриминговых платформах, поэтому сценаристы и продюсеры заинтересованы заранее знать, соответствует ли текст сценария выбранной возрастной категории. Решаемая проблема – автоматизировать анализ текста сценария на русском языке и определить корректный возрастной рейтинг, а также конкретные фрагменты, из-за которых рейтинг повышается. Это позволит авторам оперативно выявлять потенциально проблемный контент (сцены насилия, ненормативная лексика, эротика, упоминание наркотиков и пр.) и при необходимости корректировать сценарий еще на этапе разработки, экономя время и бюджет.",
          "Цель проекта: разработать веб-сервис (в первую очередь для сценаристов и продюсеров), который принимает на вход сценарий (формат .pdf или .docx), автоматически разбивает его на сцены и реплики, анализирует содержимое каждой сцены на наличие элементов, влияющих на возрастной рейтинг, и присваивает сценариям предварительный рейтинг 0+/6+/12+/16+/18+ по наиболее строгой выявленной категории. Система должна наглядно визуализировать результаты анализа по всему сценарию, помечая проблемные места, показывая долю «нарушенных» сцен, степень серьезности разных видов контента (например, None/Mild/Moderate/Severe – отсутствует/мягкий/умеренный/сильный) и выдавать пояснения и рекомендации. Пользователь получает подробный отчёт с указанием конкретных сцен/реплик, из-за которых повышается рейтинг, и рекомендациями: как снизить рейтинг (если нужно адаптировать сценарий под более младшую аудиторию) или обоснование, почему высокий рейтинг неизбежен (если это осознанное творческое решение).",
          "Система также поддерживает интерактивную доработку: пользователь может вручную отметить ложноположительные срабатывания (то есть указать, что определённая сцена не содержит нарушений, хотя была помечена системой) и добавить недостающие нарушения (если система что-то пропустила). Предусмотрен простой встроенный текстовый редактор, позволяющий вносить минимальные правки в сценарий прямо в веб-интерфейсе и повторно запустить проверку на лету. По завершении работы пользователь может сохранить результаты: формируется подробный отчёт со статистикой и визуализациями (хронология сценария с пометками, диаграммы), который можно экспортировать в формате PDF или DOCX. Кроме того, система хранит историю проверок (результаты предыдущих анализов) для последующего просмотра и сравнения."
        ],
        "children": [
          {
            "title": "Основные функции и требования",
            "level": 3,
            "content": [
              "Загрузка сценария и предварительная обработка: Пользователь (сценарист или продюсер) загружает файл сценария в формате PDF или DOCX. Система должна поддерживать различные кодировки текста (UTF-8, UTF-16, Windows-1251, KOI8-R, ISO-8859-5, MacRoman, ASCII), корректно читать кириллический текст вне зависимости от исходной кодировки. Объём сценария – до ~120 страниц (полнометражный фильм). Время полной обработки сценария среднего объёма (скажем, ~100 страниц) не должно превышать 5 минут.",
              "Сегментация на сцены и реплики: После получения текста система разбивает сценарий на логические части:",
              "Сцены: обычно в киносценарии сцены обозначаются заголовками (например, INT. КВАРТИРА – ДЕНЬ или EXT. УЛИЦА – НОЧЬ). Сервис должен обнаруживать границы сцен по стандартным паттернам сценария или структуре документа. Важно сохранить порядок сцен (хронологию истории) и их содержимое.",
              "Реплики персонажей: внутри каждой сцены необходимо различать описание действий/событий и диалоги персонажей. Сервис должен уметь выделять строки с именами персонажей и их реплики отдельно от ремарок. Это позволит при анализе понимать, где употреблена ненормативная лексика (обычно в речи персонажей) или например кто именно совершает насилие в сцене. Корректная сегментация – одна из оцениваемых метрик (точность разбиения на сцены и сохранение структуры диалогов) и должна быть максимально близка к ручной верстке сценария (до 10 баллов из критериев функциональности).",
              "Анализ содержания на нарушения: Ключевая функция backend-модуля – распознать в тексте сцены различные категории контента, влияющие на рейтинг. Согласно 436-ФЗ и общепринятой классификации, нужно обнаруживать как минимум следующие категории:",
              "Насилие и жестокость. Включает сцены драки, убийств, физических расправ; отдельно учитывается наличие крови, жестоких и шокирующих подробностей (т. н. gore).",
              "Сексуальный контент. Эротические сцены, сексуальные акты, нагота, порнография. Закон различает лёгкий романтический контент (целование, намёки) – допустим в 12+ или 16+ – и порнографические или явно возбуждающие описания – сразу 18+.",
              "Ненормативная лексика. В русском законодательстве любое употребление нецензурной брани (т. н. \"мат\") автоматически относит материал к категории 18+ (эти слова запрещены к распространению детям). Более мягкие бранные слова (например, оскорбления без мата) допустимы до определённой степени в 16+[1]. Система должна отслеживать все случаи ненормативной лексики, различая степень: от отсутствия (None) до лёгкой брани (Mild), и вплоть до присутствия мата (Severe, т.е. 18+).",
              "Алкоголь, наркотики, курение. Упоминания или тем более демонстрация употребления наркотических и психотропных веществ обычно запрещены для детских категорий. Закон 436-ФЗ разрешает показывать подобные темы в 16+ только в отрицательном контексте (осуждая)[1]; положительное или нейтральное изображение употребления наркотиков, курение детьми, пропаганда алкоголя и т.п. ведёт к 18+. Система должна выявлять случаи, где персонажи пьют алкоголь, курят или употребляют наркотики, а также где это может подаваться как норма.",
              "Пугающие и шокирующие сцены. Сцены ужаса, внезапные появления пугающих образов, описание событий, способных вызвать страх, панику или ужас у детей. Например, элементы фильмов ужасов, сцены с резким нападением, кадры, которые могут травмировать детскую психику. Закон ограничивает такие сцены: короткие умеренно страшные эпизоды допускаются с 6+ или 12+ в зависимости от натуралистичности, сильный ужас – только 16+ и 18+. Система помечает сцены, содержащие сильный хоррор-контент, монстров, детально описанные катастрофы, смерти и т.п.",
              "Помимо перечисленного, могут быть и другие категории (например, пропаганда антисоциальных действий – преступлений, терроризма, экстремизма; оскорбление родителей и пропаганда «нетрадиционных отношений» – особые случаи 18+ по российскому закону). В рамках проекта можно сосредоточиться на основных пяти шкалах (насилие, секс, лексика, наркотики/алкоголь, страх) аналогично тому, как это реализовано в разделе Parents Guide на IMDb. Важна точность определения каждого типа нарушения – необходимо по максимуму находить все эпизоды, действительно содержащие запрещённый контент (минимизируя пропуски), и в то же время избегать ложных срабатываний на нейтральные сцены. Оценка за этот пункт (полнота и точность выявления по категориям) – до 10 баллов.",
              "Оценка степени серьезности и итоговый рейтинг: Для каждого выявленного фрагмента контента система определяет градацию серьезности (например, None/Mild/Moderate/Severe). Градации могут соответствовать приблизительно возрастным категориям:",
              "None (отсутствует) – категория не представлена в сцене.",
              "Mild (мягкое проявление) – условно соответствует уровню 6+ или 12+ (не явный или кратковременный контент). Например, единичный шлепок без последствий – мягкое насилие; поцелуй – мягкий сексуальный контент; слово \"чёрт\" – мягкая лексика.",
              "Moderate (умеренно) – ближе к уровню 12+ или 16+, ощутимое наличие, но без выхода за строго запрещённые рамки. Например, драка без крови – умеренное насилие (16+); несколько грубых оскорблений без мата – умеренная лексика (может 16+); эпизод курения взрослым персонажем – умеренное (вероятно 12+ или 16+ при множественном показе).",
              "Severe (сильное, грубое) – уровень, недопустимый для детей, скорее всего 18+. Сюда относятся все случаи, автоматично ведущие к 18+: мат, порнографические описания, жестокое насилие с кровью и расчлененкой, сцены употребления наркотиков или их пропаганды и т.п.",
              "Система агрегирует всю информацию по сценарию и вычисляет итоговый возрастной рейтинг для всего произведения, основываясь на самом серьёзном эпизоде. Логика простая: возрастной рейтинг = категория самого строгого выявленного нарушения. Если хотя бы в одной сцене найдено что-то, требующее маркировки «18+», то весь сценарий получает рейтинг 18+; иначе если нет 18+, но есть элементы уровня 16+ – общий рейтинг 16+; и так далее. Эта логика должна соответствовать нормам закона и экспертной практике классификации. Корректность определения финального рейтинга – ещё один критерий оценки (до 10 баллов), проверяемый на тестовых сценариях: автоматически присвоенная категория должна совпасть с экспертизой вручную.",
              "Идентификация проблемных фрагментов: Кроме присвоения общей категории, система должна указать конкретные места сценария, из-за которых рейтинг повышается (так называемые \"проблемные\" сцены). Это поможет авторам понять, на что обратить внимание. Например, если сценарий получил 18+ из-за одного эпизода с нецензурной бранью, система пометит эту сцену и предоставит пояснение. Таких сцен может быть несколько. Они отмечаются особым образом (цветом на шкале и в тексте) и собираются в отчёте как список ключевых эпизодов с указанием причины.",
              "Генерация аннотаций и рекомендаций: Для каждой проблемной сцены сервис формирует развернутый комментарий, включающий:",
              "Текст фрагмента (например, проблемная реплика или описание – цитата либо краткое содержание).",
              "Локация в сценарии: номер сцены, а при необходимости и номер страницы/строк в документе. (Если документ PDF – можно попытаться определить страницу; в DOCX – возможно указать главу/сцену).",
              "Категория и степень нарушения: например, «Насилие: тяжелая степень (Severe) – графичное описание раны».",
              "Рекомендации по корректировке: Если предполагается снизить рейтинг – совет, как смягчить или убрать нарушение. Если же повышенный рейтинг допустим, можно включить пояснение для отчётности – почему сцена повышает рейтинг (например: «сцена содержит ненормативную лексику, что по закону требует маркировки 18+»). Рекомендации могут быть сформулированы в виде: «Чтобы снизить рейтинг до 12+, рекомендуется убрать нецензурную лексику или заменить её на нейтральные выражения.» Или: «Для аудитории 6+ сцена слишком пугающая; чтобы соответствовать 6+, следует сократить описание страшных деталей.».",
              "Генерация таких текстовых аннотаций – идеальная задача для языковых моделей (LLM). Планируется использовать LLM, чтобы на основе анализа сцены автоматически сформулировать понятные объяснения и советы по правке. Это придаёт системе экспертность, близкую к тому, как реальный редактор или цензор комментировал бы сценарий.",
              "Веб-интерфейс с визуализацией результатов: Результаты анализа должны быть представлены пользователю в удобной и понятной форме. GUI – одностраничное веб-приложение (SPA) либо динамический интерфейс – включает следующие элементы:",
              "Хронология сценария с цветовой индикацией рисков. Предполагается список или шкала всех сцен по порядку (например, нумерованный список сцен с кратким названием или первым предложением), где каждая сцена помечена цветом в зависимости от самой серьёзной категории, найденной в ней. Можно взять аналогию цветовой схемы IMDb Parents Guide[2]: зелёный (None) – нет нарушений, жёлтый – Mild, оранжевый – Moderate, красный – Severe. Таким образом, взглядом можно охватить, где в сценарии находятся проблемные зоны: если вся шкала зелёная кроме одного красного блока в середине – значит почти весь сценарий чистый, кроме одной очень жёсткой сцены.",
              "Процентное соотношение чистых/нарушенных сцен. Дополнительно к цветовой шкале, полезно показать метрику: например, «Сцен с нарушениями: 5 из 50 (10%)». Можно также разбить по уровням: «умеренные/серьёзные нарушения в 3 сценах (6%)». Это соответствует требованию отображения доли сцен с теми или иными нарушениями.",
              "Сводка по категориям (Parents Guide style). Отдельный блок интерфейса отводится под список категорий нарушений с указанием степени и статистики по каждой:",
              "Например: Насилие: Умеренно (3 эпизода, 10% сцен). Ненормативная лексика: Серьёзно (1 эпизод, 2% сцен). Сексуальный контент: Нет. Алкоголь/наркотики: Мягко (2 эпизода). Страх: Умеренно (1 эпизод).",
              "Каждая категория можно отобразить строкой или значком с цветом. Рядом – количественная информация: сколько эпизодов выявлено, в скольких сценах. Также показывается обобщённая степень (None/Mild/Moderate/Severe) для всей картины.",
              "По нажатию на категорию пользователь может раскрыть список конкретных эпизодов. Например, нажимая «Насилие: Умеренно», развернётся перечень сцен с насилием: краткое описание каждой (как в Parents Guide на IMDb, где перечисляются моменты фильмов с насилием). Система должна автоматически сгенерировать такие описания эпизодов: «Сцена 5: драка без крови, герой ударяет противника кулаком (умеренное насилие).»; «Сцена 12: герой угрожает оружием, выстрелов нет.» и т.п. Эти описания берутся из анализа сцен LLM-моделью.",
              "Таким образом, продюсер видит не просто сухой факт «насилие есть», а конкретно какие сцены и в чём проявляется, что облегчает оценку возможности исправить сценарий.",
              "Детальный просмотр сцены. В интерфейсе можно предусмотреть, что при клике на конкретную сцену в списке хронологии открывается подробная информация: текст сцены (или отрывок), и все метки категорий внутри неё. Например, если в сцене 8 присутствует нецензурная реплика, интерфейс может подсветить её в тексте другим цветом и показать метку «Language: Severe». Пользователь таким образом может прочитать проблемное место в контексте полной сцены. Встроенный просмотр текста также пригодится для редактора (см. ниже).",
              "Интерактивная корректировка результатов: Пользовательский контроль качества:",
              "Для каждого отмеченного системой нарушения должен быть инструмент «пометить как ложное». Например, рядом с описанием эпизода или прямо на таймлайне сцены – кнопка или чекбокс «False Positive / Ложное срабатывание». Если пользователь считает, что система ошибочно классифицировала фрагмент как нарушение, он может отключить его. После этого система пересчитает итоговый рейтинг с учётом того, что этот эпизод исключён.",
              "Аналогично, должен быть способ добавить пропущенное нарушение. Пользователь может выделить фрагмент текста в сцене и вручную указать категорию и степень, если уверен, что система его пропустила. Например, если система не распознала завуалированный намёк на наркотики, пользователь выделяет эту реплику и задаёт «Drugs: Moderate». Новый эпизод добавится к данным анализа, что может повысить рейтинг.",
              "После любых правок (исключения или добавления эпизодов) итоговый сводный рейтинг и статистика мгновенно пересчитываются. Благодаря этому пользователь может добиться максимальной точности отчёта перед финальным экспортом. Также эти действия позволяют собирать данные для последующего улучшения модели (отмечая, где модель ошиблась).",
              "Редактирование сценария и повторная проверка: Встроенный простой текстовый редактор позволяет на месте подправить сценарий. Это актуально, если автор, увидев замечания системы, решает внести правки (например, заменить матерное слово на мягкое). Интерфейс редактора может быть реализован как переключение режима просмотра сцен на режим редактирования текста – например, показывать текст сценария постранично или сценами и позволять править текстовые блоки. Допускаются простейшие текстовые правки (это не полноценный Word-редактор, а минимальный редактор для текста). После внесения изменений пользователь может нажать «Повторно анализировать». Система пересканирует только изменённые части или весь сценарий и обновит результаты. Важно, чтобы повторная проверка была относительно быстрой (возможно, за счёт повторного использования загруженной модели в памяти, без инициализации заново). Таким образом, цикл «правка → анализ» замыкается прямо в веб-приложении, без необходимости выгружать документ и загружать снова.",
              "Экспорт отчёта: Пользователь может скачать итоговый отчёт двумя способами: DOCX (Word) или PDF. Отчёт должен содержать всю ключевую информацию:",
              "Заголовок с названием сценария (можно взять из имени файла) и определённым рейтингом (например, «Возрастной рейтинг: 16+»).",
              "Краткое резюме: какие категории контента найдены, в какой степени (например, как в IMDb: Violence – Moderate, Profanity – Severe и т.д.).",
              "Статистические графики или таблицы: например, круговая диаграмма распределения сцен по категориям (чистые vs с нарушениями), гистограмма по количеству эпизодов каждого типа. В PDF можно вставить изображения графиков, сгенерированные на backend. В DOCX – либо встроить изображения, либо использовать форматирование таблицами и диаграммами Word.",
              "Список проблемных сцен с подробными аннотациями: по каждой – номер сцены, цитата (или краткий пересказ) проблемного момента, категория/степень, рекомендация по исправлению. Этот список является основным «выводом» для сценариста.",
              "Возможно, приложить полный хронологический список сцен с отметками (например, таблицу: № сцены – наличие нарушений по категориям).",
              "Отчёт оформляется читабельно, с подзаголовками, цветовыми акцентами (в PDF) – этот пункт оценивается на читабельность и структурированность (до 10 баллов за экспортируемый отчёт).",
              "Хранение истории проверок: Поскольку приложение однопользовательское (каждый развёртывает для себя, без авторизации), можно хранить историю прямо локально. Тем не менее, важно, чтобы результаты прошлых анализов не пропадали. Система сохраняет в базе данных или файлах информацию о каждом анализе: дата/время, название файла сценария, итоговый рейтинг, основные статистики и ссылки на сохранённые отчёты (PDF/DOCX). В интерфейсе можно добавить вкладку «История» – список прошлых проверок. Пользователь может открыть запись из истории, чтобы посмотреть результаты (например, сравнить старую версию сценария с новой).",
              "Выбор и настройка языковой модели: Особенность – все модели работают локально, без обращения к внешним API (ограничение заказчика). Это значит, что библиотека и весовые файлы моделей будут развёрнуты на сервере, скорее всего используя GPU. Ограничение объёма моделей – суммарно до 80 ГБ видеопамяти (VRAM). Это достаточно большой бюджет, позволяющий использовать современные LLM среднего размера. Однако для повышения гибкости заложена возможность подключить модели через OpenRouter (если у пользователя есть доступ к сторонним API, например OpenAI GPT-4). Мы реализуем модульный подход: две опции inference – локальная (offline) и внешняя через API:",
              "Локальная модель: будет использоваться по умолчанию. Например, возможен выбор открытой модели, умеющей понимать русский язык и выполнять классификацию и генерацию. Рассматриваются LLaMA-2 (или аналогичные) с дообучением под задачи анализа контента. Модель на 13B или 33B параметров в сжатом виде может поместиться на 80 ГБ VRAM. Согласно опыту, 70-миллиардную LLaMA 2 можно запустить на ~48–60 ГБ VRAM при 4-битном квантуовании[3], а 33B и тем более 13B – тем более помещаются. Таким образом, можно загрузить одну большую модель (~13–33B) сразу, чтобы она выполняла и классификацию, и генерацию текста по очереди. Либо использовать комбинацию моделей: например, более лёгкую модель-классификатор (на основе RuBERT или XLM-R) для быстрого меткого определения категорий по сценам, и небольшую диалоговую модель (например, 7B LLM) для генерации текстовых пояснений. Все эти модели хранятся и работают локально, без интернета.",
              "Через OpenRouter API: это опциональный режим, переключаемый в интерфейсе настроек. OpenRouter предоставляет единый интерфейс к различным LLM (GPT-4, Claude и др.). Если пользователь выберет его и укажет API-ключ, то при анализе текста запросы на классификацию и генерацию рекомендаций будут направляться к внешним моделям. Это может повысить качество анализа (например, GPT-4 может точнее уловить контекст), но требует подключения к интернету и не соответствует требованию автономности. Поэтому эту функцию используем только как опцию для пользователя. По умолчанию решения должны проходить все критерии в offline-режиме.",
              "Ограничения производительности: Временные рамки – 5 минут на сценарий среднего объёма (~20–30 тысяч слов). Для достижения этого backend должен эффективно использовать ресурсы:",
              "Загрузка и разбор файла – секунды.",
              "Сегментация – миллисекунды или секунды (простой разбор строк или с помощью регулярных выражений).",
              "Классификация содержимого – потенциально самая тяжёлая часть, т.к. подразумевает прогнать текст через модель(и). Возможные оптимизации: не обрабатывать каждый символ через LLM. Можно сначала выполнить быстрый фильтр: например, словарь триггеров. Пробежать по тексту сцен и отметить сцены, где встречаются подозрительные ключевые слова (список матерных слов, «кровь», «убил», названия наркотиков и т.п.). Сцены, где не найдено ничего подозрительного, можно сразу пометить как безопасные (0+) либо проанализировать минимально. А вот сцены с найденными триггерами – отправить в модель для детального анализа и определения степени. Это сократит количество обращений к модели.",
              "Параллелизация: если позволяет GPU, можно обрабатывать несколько сцен параллельно (например, батчами) или воспользоваться многопоточностью CPU для независимых стадий.",
              "Кеширование: если пользователь часто перезапускает анализ с мелкими правками, можно кешировать результаты предыдущего анализа и обновлять дифференциально. Однако, учитывая возможные перестановки текста, проще на каждый запуск анализировать заново.",
              "Фактическая генерация отчёта (рендеринг PDF/DOCX) должна занимать секунды. Используем эффективные библиотеки (ReportLab, python-docx) и не генерируем слишком большие изображения.",
              "Ниже описываются технические решения по реализации данной функциональности, включая выбор стеков технологий, архитектуру приложения, модули backend и подробный дизайн GUI."
            ],
            "children": []
          }
        ]
      },
      {
        "title": "Технологический стек и ключевые инструменты",
        "level": 2,
        "content": [
          "Для реализации веб-приложения на Python и соблюдения всех требований выберем современный и проверенный стек технологий:",
          "Backend: фреймворк FastAPI (Python). Этот лёгкий асинхронный веб-фреймворк отлично подходит для сервисов, включающих вызовы моделей ИИ. Он позволяет легко организовать REST API эндпоинты (для загрузки файла, получения результатов, скачивания отчёта), поддерживает WebSocket (при необходимости стриминга промежуточных результатов), и имеет высокую производительность. Кроме того, FastAPI способствует чистой архитектуре: поддержку dependency injection, удобную встраиваемость модулей и логики, и хорошо сочетается с Pydantic (для определения моделей данных, например, схемы результата анализа). Выбор в пользу FastAPI обусловлен тем, что он минималистичнее Django (не требуется тяжелый ORM или шаблоны) и более пригоден для RESTful API, которые будут обслуживать SPA фронтенд. Также сообщество FastAPI активно применяет чистую архитектуру с разбиением на роутеры по фичам.",
          "ML/LLM: библиотека Hugging Face Transformers (и PyTorch как бэкенд). Transformers – де-факто стандарт для работы с языковыми моделями локально. Через неё мы можем загрузить нужную русскоязычную модель (например, XLM-Roberta или специально обученные модели для content moderation), а также большие GPT-подобные модели (например, LLaMA2) для генерации. HuggingFace предоставляет удобный API для токенизации, ускоренную работу с GPU, поддерживает 8-битные и 4-битные веса через библиотеки типа BitsAndBytes, что нам пригодится для экономии VRAM. Также, при необходимости, можно использовать открытые модели от SberDevices (например, ruGPT-3 семьи) или модели на базе LLaMA, уже дообученные на русском (это проще интегрировать, чем писать собственный трансформер). Все они совместимы с Transformers.",
          "NLP утилиты: для некоторых задач применим SpaCy или Natasha (русскоязычный NLP), если понадобится токенизация, лемматизация или rule-based matching (например, обнаружение именованных сущностей, или проверка списка нецензурных слов с учётом морфологии). Например, список матерных слов в русском языке может быть закодирован через pattern-мatcher SpaCy, чтобы учитывать формы слов (окончания). Также RegEx (модуль re) будет использоваться для структурного парсинга сценария (поиск сцен INT./EXT., имен персонажей (в сценариях имена героев часто пишутся ВЕСЬМА), разделение диалогов).",
          "Парсинг PDF/DOCX:",
          "Для PDF: библиотека PyMuPDF (fitz) или pdfplumber. PyMuPDF хорошо зарекомендовала себя для извлечения текста с сохранением разбивки по страницам и даже координатами. Нам важно получить чистый текст, при этом, если возможно, знать границы страниц (для отчёта). Будем использовать PyMuPDF для PDF.",
          "Для DOCX: библиотека python-docx для извлечения текста и структуры. DOCX хранит параграфы, стили – возможно, сценарий в DOCX размечен стилями (например, стиль «Scene Heading»). Если так, можно использовать это для сегментации. В общем случае, python-docx даст последовательность параграфов текста, которую мы анализируем на ключевые слова (INT./EXT., персонаж: и т.д.).",
          "Кодировки: для DOCX и PDF, библиотеки обычно сами справляются, но на всякий случай после извлечения текста приведём его к UTF-8. Если будет plain text input (теоретически), тоже примем.",
          "Database и хранение данных: используем SQLite как встроенную базу данных для хранения истории анализов и, возможно, для хранения параметров (например, шаблонные тексты рекомендаций, если вынесем их, или логи). SQLite не требует установки сервера и отлично подходит для однопользовательского приложения. Объём данных небольшой (только текстовые отчёты, статистика). Можно использовать ORM (например, SQLAlchemy) для удобства, но допустимо и прямые SQL запросы, учитывая малую сложность схемы (пара таблиц: analyses, analysis_issues и т.п.). SQLite файл будет храниться рядом с приложением или в указанной папке, и может бэкапиться. Альтернатива: хранить историю в виде файлов (например, сохранять JSON каждого результата или сразу готовые отчёты PDF), а в базе лишь индексы – тоже вариант, но мы реализуем через БД для возможности фильтрации/поиска по истории.",
          "Frontend: веб-клиент будет создан как одностраничное приложение. Выбор технологий фронтенда:",
          "Фреймворк React (JavaScript/TypeScript) – наиболее популярный вариант для SPA. Он позволит создать динамичный интерфейс, реагирующий на обновления данных (например, после анализа или правок). TypeScript предпочтителен для поддерживаемости кода.",
          "UI-библиотека – чтобы быстрее сверстать интерфейс, возьмём готовый набор компонентов, например Ant Design или Material-UI. Они предоставят таблицы, всплывающие панели, индикаторы прогресса, цветные теги и т.д., что нам пригодится для визуализации категорий (например, компонент тегов с разными цветами для None/Mild/Moderate/Severe).",
          "Графики и визуализации: используем Chart.js или Recharts для диаграмм (процент сцен, распределение по категориям). Для таймлайна сцен можно реализовать кастомно (список элементов с цветным индикатором), либо использовать библиотеку timeline (например, vis-timeline или просто стилизованный список).",
          "Редактор текста: для простоты можно применить готовый компонент типа Draft.js или Slate (React библиотеки для rich text), но с учётом требований достаточно простого textarea. Возможно, удобнее даже открыть исходный DOCX в окне Word – но это уже вне браузера. Поэтому реализуем примитивно: переключаем сцену в режим редактирования, заменяя абзацы на contenteditable div.",
          "Взаимодействие с backend по API: через HTTP REST. Файлы загружаются POST-запросом, анализ запускается и либо сразу возвращает результат, либо (если долго) возвращает задачe-id и далее фронт опрашивает состояние (polling) или открывает WebSocket для прогресса. Мы можем реализовать polling: после отправки файла бэкенд сразу отвечает «анализ начат, ид задачи 123». Фронтенд раз в N секунд спрашивает /analysis/123/status и получает процент или этап. По готовности – забирает результаты JSON. Альтернативно, можно синхронно подождать с индикатором загрузки – FastAPI позволит обрабатывать 5 минут запрос, но лучше не держать соединение так долго. Поэтому, вероятно, сделаем фоновые задачи.",
          "Фоновые задачи: интегрируем Celery (с Redis, например) или используем встроенные background-tasks FastAPI. Celery более мощный (можно масштабировать на несколько воркеров, если понадобится), но для однопользовательской версии, где одновременно одна задача, можно обойтись упрощённо. Опишем в архитектуре.",
          "Docker-контейнеризация: для облегчения деплоя и запуска на любой ОС подготовим Dockerfile. Он будет содержать:",
          "Базовый образ Python (например, 3.10 slim) + необходимые apt-пакеты (Poppler/pdfium для PDF, ffmpeg если нужен, возможно GraphViz для отрисовки диаграмм, но лучше генерировать графики в коде).",
          "Установка зависимостей pip (FastAPI, Uvicorn, Transformers, Torch, numpy, pandas, etc., plus front-end build if needed).",
          "Копирование кода приложения.",
          "Запуск Uvicorn сервера.",
          "Для GPU-версии – базовый образ с CUDA (nvidia/cuda + pytorch) и требование запускать с --gpus all. Инструкции для пользователей: либо использовать docker-compose, где прописан volume для моделей (чтобы не тянуть 80ГБ при каждом билде), либо предоставлять свои веса отдельно.",
          "Докер обеспечивает переносимость (запуск на Windows/Mac/Linux с минимальными усилиями).",
          "Альтернативно или в дополнение: инструкция по локальному запуску (с виртуальным окружением), но Docker предпочтительнее.",
          "Прочие утилиты и решения:",
          "Настройка LLM: Будем использовать оптимизации вроде torch.cuda.amp (автоматическое смешанное точное вычисление), 8-bit/4-bit quantization (через bitsandbytes) для крупных моделей. Это сократит использование VRAM и немного ускорит работу.",
          "Логгирование: встроим логирование (модуль logging) для отслеживания процесса анализа (чтобы при отладке видеть, на каком шаге сколько времени ушло, где возможные узкие места).",
          "Тестирование: Напишем юнит-тесты для критичных функций: парсер сценария (проверить, что правильно делит сцены, распознает реплики), классификатор (на подготовленных примерах фраз проверяет категорию), сборщик отчёта. Это упростит отладку и улучшит надёжность.",
          "Безопасность: так как у нас нет авторизации и приложение локальное, вопросов безопасности мало. Однако, учтём, что при загрузке файла, особенно DOCX, могут быть макросы или вредоносный контент – лучше явно игнорировать постороннее содержимое и обрабатывать только текст. PDF тоже может содержать скрипты, но PyMuPDF, как правило, только текст достаёт.",
          "Конфигурация: Предусмотрим файл настроек (JSON или .env), где можно указать: путь к модели/весам, желаемый вариант модели (например, small/medium), включён ли OpenRouter и ключ API, параметры тонкой настройки (например, пороги срабатывания для moderate vs severe – можно вынести в конфиг, чтобы подправить без перекомпиляции).",
          "Выбор технологий обоснован стремлением сделать систему масштабируемой, поддерживаемой и расширяемой. Применение принципов Clean Architecture позволит изолировать бизнес-логику анализа сценария от деталей фреймворков. Такой подход повышает модульность, облегчает тестирование и дальнейшее развитие[4]. А организация кода по feature-first (фиче-ориентированная структура) обеспечивает, что каждая крупная функция (анализ, отчёты, UI) станет самостоятельным модулем со всеми необходимыми слоями реализации[5]. Это упростит командную разработку и добавление новых возможностей без ухудшения структуры проекта."
        ],
        "children": []
      },
      {
        "title": "Архитектура системы (общая схема)",
        "level": 2,
        "content": [
          "На высоком уровне систему можно представить как классическое клиент-серверное приложение с выделенным модулем анализа на базе ML. Ниже приведена схема основных компонентов и их взаимодействия:",
          "Рис. 1: Общая архитектура веб-приложения. Веб-клиент (React) общается через REST API с Python backend (FastAPI). Аналитический модуль внутри backend выполняет разбор сценария и применение ML/LLM моделей. Локальная база данных хранит историю и результаты. В зависимости от настройки, модуль анализа либо использует локальные весовые модели (на GPU сервере), либо делает запросы к внешнему API (OpenRouter) для получения результатов. Вся тяжелая обработка изолирована на стороне сервера, UI получает уже обработанные данные.",
          "Основные компоненты на схеме: - Web UI (Frontend): одностраничное приложение, работающее в браузере. Отвечает за отображение интерфейса, отправку файла сценария на сервер, получение результатов анализа (в формате JSON) и интерактивное взаимодействие с пользователем (правки, перезапуск, выгрузка). UI не занимается какой-либо сложной логикой – все проверки и вычисления происходят на сервере. - FastAPI Backend: веб-сервер на Python, реализующий REST API эндпоинты: - POST /analyze – загрузка сценария (файл) и запуск анализа. Может быть реализован как асинхронный запрос, возвращающий сразу результат, либо как запуск фоновой задачи и возвращение ID задачи. - GET /analysis/{id} – получение результатов анализа (если через задачу). - POST /analysis/{id}/feedback – при отправке ручных корректировок (ложноположительные/ложноотрицательные). - POST /analysis/{id}/edit – при повторном запуске после правок (либо можно объединить с /analyze). - GET /report/{id}.{pdf|docx} – скачивание сгенерированного отчёта. - GET /history – получение списка прошлых анализов. - Плюс статическая раздача фронтенда (файлы React билда) или отдельный хостинг фронта.",
          "FastAPI организует контроллеры, вызывающие соответствующие функции приложения (use-cases). Он не содержит бизнес-логики напрямую – только обработка HTTP и сериализация/десериализация. Это соответствует принципу \"независимость UI от логики\" в чистой архитектуре[6].",
          "Модуль анализа (Analysis Engine): ядро системы, где происходит вся \"магия\". Это совокупность компонентов:",
          "Парсер сценария – функции для извлечения текста из PDF/DOCX, очистки, сегментации на сцены и реплики. Выдают структурированные данные (например, список объектов Scene, каждый содержит scene_number, text, dialogues[] и т.п.).",
          "Классификатор контента – набор алгоритмов/моделей, которые получают на вход текст сцены (или даже побитово по репликам) и возвращают метки по категориям: Violence=?, Sex=?, Language=?, Drugs=?, Fear=? – вместе с градацией (None/Mild/Moderate/Severe). В реализации это может быть несколько разных моделей или одна мультиклассовая:",
          "Например, функция analyze_scene(scene_text) -> dict{category: severity}. Внутри может сначала вызвать rule-based детектор, потом LLM для более тонкой оценки, или сразу использовать предобученную модель, выдающую вероятности по классам.",
          "Логика присвоения рейтинга – функция, агрегирующая результаты по всем сценам. Реализует правила: определяет максимальную категорию (0/6/12/16/18) на основе самых серьёзных обнаруженных нарушений. Эта часть фактически кодирует знание норм 436-ФЗ (например: если Language=Severe найдено где-либо, то рейтинг = 18+; иначе если Violence=Moderate где-то, то >=16+ и т.д.). Здесь же помечаются «проблемные сцены» – те, которые содержат нарушения на уровне финального рейтинга.",
          "Генератор пояснений – компонент, формирующий текстовые описания. Может использовать LLM (через трансформер) для генерации рекомендаций по каждой проблемной сцене, а также суммарных описаний категории. Например, для каждого эпизода с насилием создать одну-две фразы описания. Если LLM тяжелая, можно объединить запрос: сразу сгенерировать все описания по списку обнаруженных проблем (контекстом давать модель список проблемных мест, чтобы она выдала форматированное объяснение). Также возможно зафиксировать шаблоны для некоторых рекомендаций, особенно очевидных (мат -> «убрать/заменить брань»).",
          "Формирование структуры результатов – собрать все данные в едином объекте AnalysisResult. Это будет большой JSON со вложенностью:",
          "{  \"final_rating\": \"16+\",  \"categories\": {    \"violence\": {\"severity\": \"Moderate\", \"count\": 3, \"percent_scenes\": 10},    \"profanity\": {\"severity\": \"Severe\", \"count\": 1, \"percent_scenes\": 2},    ...  },  \"scenes\": [    {\"number\": 1, \"issues\": []},     {\"number\": 2, \"issues\": [{\"category\": \"Drugs\", \"severity\": \"Mild\", \"text\": \"герой курит сигарету\"}]},     ...  ],  \"problems\": [     {\"scene\": 5, \"category\": \"Violence\", \"severity\": \"Moderate\", \"description\": \"Драка, удар кулаком\", \"recommendation\": \"Смягчить насилие...\"},     {\"scene\": 7, \"category\": \"Profanity\", \"severity\": \"Severe\", \"text\": \"нецензурная фраза ...\", \"recommendation\": \"Удалить/заменить грубое слово...\"}  ]}",
          "Такая структура затем используется и для отображения на фронтенде, и для генерации отчёта.",
          "Обработка ручных правок: модуль анализа может повторно применяться при корректировке. Например, если пользователь пометил эпизод как ложный, достаточно убрать его из problems и пересчитать рейтинг. Если добавил новый – добавить и тоже пересчитать. Эти операции быстрые (не требуют повторного запуска модели, если пользователь сам указал категорию). А вот если после текстовых правок – нужно заново прогнать анализ, но можно оптимизировать, проанализировав только изменённую сцену или близлежащие.",
          "Модуль анализа спроектирован так, что его функции можно вызывать из разных контекстов (из веб-запроса, из фонового задания). Он не зависит от FastAPI – чисто логика. Это позволяет изолированно тестировать его, а также, теоретически, вынести в отдельный сервис (микросервис), если потребуется масштабировать.",
          "Хранилище данных (Database/Storage): Приложение сохраняет результаты анализов и связанные артефакты. Как отмечалось, выбрана SQLite база.",
          "Таблица Analyses: id, filename, date, final_rating, categories_overview (м.б. JSON или отдельные поля), report_path (ссылки на сохранённый PDF/DOCX).",
          "Таблица Issues: связь с Analysis, сцена, категория, severity, description, recommendation (все текстом). Эти данные фактически дублируют то, что есть в JSON результирующем, и служат для построения отчётов и интерфейса истории без повторного анализа.",
          "При сохранении отчёта PDF/DOCX, файл кладётся, например, в reports/analysis_{id}.pdf.",
          "История хранится автоматически при каждом запуске анализа. Если пользователь повторно анализирует тот же сценарий после правок, это будет новая запись (можно поле original_analysis_id сделать, если хотим связь версий).",
          "В будущем можно сменить движок БД на PostgreSQL или другую, и благодаря слою абстракции (ORM) это не повлияет на остальную систему[7].",
          "Внешние API (опционально): на схеме помечен блок OpenRouter API. Если активирован режим внешней модели, модуль анализа посылает запросы (например, HTTP POST с промптом) к OpenRouter endpoint. Это делается через интернет и может занимать время, поэтому такие вызовы тоже лучше выносить во внутренние асинхронные задачи, чтобы не блокировать основной поток.",
          "Фоновые задачи и очереди: По необходимости, backend может поднимать отдельный воркер-процесс (через Celery или просто Uvicorn thread) для выполнения анализа. Тогда запрос POST /analyze мгновенно возвращает ID задачи, а сам анализ происходит асинхронно. Клиент ждёт, опрашивает. Это удобно, если время 5 минут – чтобы не держать HTTP соединение. Впрочем, FastAPI с Uvicorn мог бы и обработать 5 минут, но тогда нужно увеличить таймауты и т.д.",
          "Мы склонны внедрить Celery с брокером (Redis). Он позволит также планировать, например, очистку старой истории, подготовку отчётов в фоновом режиме.",
          "В простейшем варианте, можно использовать BackgroundTasks из FastAPI, которые выполнят задачу после отправки ответа. Но нам нужен прогресс и результат – тут Celery более уместен.",
          "В рамках MVP можно не усложнять и просто дождаться результат в одном запросе, показывая на фронте индикатор загрузки (браузер будет ждать ответ). Но UX хуже, поэтому скорее реализуем асинхронно.",
          "Принципы чистой архитектуры: Код будет разделён на слои: - Domain entities – основные сущности: Scene, Issue, AnalysisResult. Простые dataclass или Pydantic-модели, которые переносят данные между слоями. - Use cases (Interactors) – операции: ParseScript, AnalyzeScript, GenerateReport, ApplyFeedback. Каждая реализована как отдельный сервис (класс или функция), оперирующий сущностями. Они не зависят от веб-фреймворка или БД – только от Domain. Например, AnalyzeScript принимает на вход объект сценария (список сцен) и возвращает объект результата анализа. - Interface Adapters – слой, соединяющий use-case с внешними интерфейсами. Сюда входят: - Реализация репозиториев/DAO для сохранения и загрузки истории (например, AnalysisRepository с методами save(AnalysisResult) и get_history()) – внутренняя реализация на SQLite. - Классы доступа к LLM – например, LocalModelLLM и OpenRouterLLM, реализующие единый интерфейс LLMService с методами classify(text) и generate(text, prompt_type). Use-case AnalyzeScript будет работать с LLMService абстрактно, не зная, какой именно класс под ним (это позволяет легко переключать локальную модель на API)[6]. - Адаптеры для файлов – FileParser интерфейс с реализациями PDFParser и DocxParser. Use-case ParseScript вызывает parser.parse(file), не заботясь о формате. - Веб-адаптеры (контроллеры FastAPI) – принимают HTTP, вызывают соответствующий use-case, затем результат преобразуют в JSON-схему (либо используют Pydantic BaseModel, которая может быть определена на уровне интерфейса).",
          "Frameworks & Drivers (External) – самый внешний слой: сам FastAPI, Celery, SQLite (через конкретную библиотеку), HuggingFace (вызовы моделей). Они внедряются через зависимости. Например, выбор локальной или удалённой LLM модели решается при старте приложения: если настроено локально – инициализируем модель и передаем объект LocalModelLLM внутрь сервиса; если API – другой объект.",
          "Такое разбиение гарантирует, что, скажем, заменить FastAPI на другой фреймворк (или добавить gRPC API параллельно) можно без переписывания логики анализа, а сменить модель или способ хранения – не затронет остальную систему. В результате система получается гибкой для изменений и расширений[8][9]. Для нашего проекта это важно, так как могут появиться новые требования (поддержать другую языковую модель, другую нормативную базу для рейтингов и т.д.)."
        ],
        "children": []
      },
      {
        "title": "Модуль анализа сценария: стадии и алгоритмы",
        "level": 2,
        "content": [
          "Теперь подробно рассмотрим, как осуществляется автоматический анализ текста сценария на возрастные ограничения. Модуль анализа выполняет последовательность этапов, каждый из которых преобразует или обогащает данные сценария, приближая нас к получению итогового рейтинга. Ниже представлена блок-схема процесса:",
          "Рис. 2: Блок-схема последовательности анализа сценария. Процесс начинается с загрузки файла сценария и проходит через этапы извлечения текста, сегментации, анализа контента, определения рейтинга, подготовки результатов и визуализации в UI. Пользовательские действия (обратная связь, редактирование) могут внести изменения, после чего анализ обновляется и цикл повторяется. Наконец, по запросу выполняется экспорт отчёта.",
          "Разберём эти этапы подробнее:"
        ],
        "children": [
          {
            "title": "1. Извлечение текста и предварительная обработка",
            "level": 3,
            "content": [
              "Входные данные: файл формата PDF или DOCX, загруженный пользователем.",
              "Парсинг файла: - Если это PDF, применяем PyMuPDF: открываем документ, проходим по страницам и извлекаем текст постранично. Стоит учитывать, что сценарии в PDF могут иметь два столбца или особое форматирование, но обычно сценарий – одноколоночный текст с диалогами, выровненными по центру. PyMuPDF вернёт текст блобом. Мы сохраняем помимо текста и информацию о границах страниц (для последующего указания страниц фрагментов). - Если DOCX, используем python-docx: получаем все параграфы. Иногда полезно смотреть на стилевые свойства: например, заголовки сцен могут быть в верхнем регистре и иметь стиль Heading или просто быть в формате INT./EXT. – это мы будем ловить регулярным выражением, поэтому стиль можно не учитывать. Важнее правильно сконкатенировать текст по сценам.",
              "Нормализация кодировки: приводим полученный текст к единой кодировке UTF-8 (в Python 3 строки уже Unicode). Если встречаются нераспознанные символы (вопросительные знаки вместо букв из-за несовпадения кодировки), возможно, нужно явно указать кодировку. Например, в txt-файлах CP1251 придётся указать encoding='cp1251'. Для PDF/docx такие проблемы маловероятны – они содержат Unicode.",
              "Очистка текста: удаляем неподходящие элементы: - В PDF могут встречаться колонтитулы, номера страниц. Например, если скрипт в PDF с номерами страниц, PyMuPDF может захватить их. Мы можем попытаться вырезать: если на строке только число – вероятно номер страницы, удалить. - Убедимся, что переносы строк корректны: иногда PDF выдаёт разрыв строки по окончании каждой текстовой строки. Сценарий форматируется специфически (строка не более определённой длины). Нужно реконструировать параграфы: например, если текст обрывается не на пунктуации, а просто на правом крае – возможно, следует склеить с следующей строкой. Но можно этого и не делать, а сразу переходить к шагу сегментации, т.к. он будет искать маркеры сцен/диалогов, и лишние разрывы ему не сильно помешают.",
              "Результат этапа: сплошной текст сценария (возможно, со структурой по параграфам или страницам). Далее он передаётся в модуль сегментации."
            ],
            "children": []
          },
          {
            "title": "2. Сегментация на сцены и реплики",
            "level": 3,
            "content": [
              "Разбиение на сцены:Сценарии фильмов имеют относительно формализованный формат: - Каждая новая сцена часто начинается с SCENE HEADING – строка вида INT. или EXT. (интерьер или экстерьер), затем местоположение и время суток. Например: INT. ОФИС КОМПАНИИ - ДЕНЬ. Иногда сцену может обозначать только название локации, но стандарт предполагает INT/EXT. Мы используем регулярное выражение: начало строки, возможно номер сцены, затем INT или EXT (или их русские эквиваленты, но в индустрии обычно используют английские сокращения даже в русских сценариях), затем точка, потом произвольный текст, тире, время (ДЕНЬ/НОЧЬ/ВЕЧЕР/УТРО). - Некоторые сценарии (особенно сериалов) могут нумеровать сцены явно: 1. INT. ... или писать локацию заглавными. Мы учтём такие варианты. - Итак, проходим по тексту и находим все строки, удовлетворяющие regex сцен. Для каждой такой позиции отрезаем текст до следующей такой же – это блок сцены. - Возможны случаи, когда INT. встречается в диалоге (маловероятно) или в описании (например, \"Интерьер комнаты описан ...\"). Чтобы избежать ложного срабатывания, можно требовать точное соответствие шаблону. Также, если сценарий нестандартно оформлен (например, пьеса, без INT/EXT), придётся тогда делить по другим признакам (но раз ТЗ говорит «стандартизированного сценария», видимо формат классический киносценарий). - Сохраняем для каждой сцены: ее порядковый номер (по порядку нахождения, или можно парсить номер если указан), заголовок (строка INT/EXT ...), текст сцены (включая диалоги). - Желательно также знать, на каких страницах PDF эта сцена – это можно определить, если у нас был текст по страницам: как только сцена начинается на стр X, а следующая сцена на стр Y, значит сцена занимает страницы X-Y-1. Можно потом для каждого проблемного эпизода сказать «стр. 37».",
              "Выделение реплик и описаний:Внутри каждой сцены текст делится на: - Имя персонажа: обычно пишется в центре строки заглавными буквами (например, МИХАИЛ: или просто АННА). За ним может идти реплика персонажа на следующих строках, возможно с отступом. - Ремарки (описания действий): обычный абзац текста с нормальным отступом слева (в сценариях форматировки: описания – в ширину страницы, диалоги – с отступом ~3 инча). Но при простом текстовом парсинге, мы можем ориентироваться на заглавные слова: если строка полностью в верхнем регистре и не слишком длинная (1-3 слова) – вероятно имя персонажа. - После имени персонажа могут быть в скобках указания (например, (шёпотом)), которые относятся к реплике. - Мы можем построить простейший парсер: для каждого параграфа в сцене: - Если он MATCH ^[A-ZА-ЯЁ\\s]+:$ (все большие буквы + двоеточие) или ^[A-ZА-ЯЁ\\s]+$ вся строка caps – это персонаж. Создаём новую текущую реплику с этим говорящим. - Если строка после этого не пустая и не новый персонаж, относим её как текст реплики (даже если она на несколько строк – сможем склеить до следующего имени). - Если строка в скобках – обозначение тона или действия внутри диалога – можно прикрепить к реплике, но для нашего анализа это не критично, можно игнорировать или пометить как часть описания. - Если параграф не caps – это описание (часть action). Мы можем его собирать либо цельным блоком, либо хранить построчно. Для анализа ненормативной лексики и т.д. важно, в речи или в описании находится слово (например, мат в речи персонажа или в авторском описании – с точки зрения рейтинга одинаково запрещено, но может быть интересно). - В итоге, структура данных:",
              "Scene {  number: int,  heading: str,  dialogues: List[ Dialogue { character: str, lines: [str] } ],  action: List[str]  # описания вне диалогов}",
              "Сцены можно хранить в списке или словаре по номеру.",
              "Проверка корректности сегментации: - Подсчитаем получившееся число сцен, сравним с ожидаемым (например, обычно ~40–60 сцен в фильме). Если мы получили 5 сцен на 100 стр, значит regex не сработал – нужно дебаг: возможно, сценарий не имел INT/EXT (например, телесценарий без явных сцен?). На крайний случай, если формат неизвестен, можно просто каждые N страниц делать сцену, но лучше ручной режим: если не удалось сегментировать – считать весь сценарий одной сценой. - Реплики: выведем статистику, сколько диалогов распознано. Если 0, значит, либо не было, либо парсер не сработал. Можно игнорировать – анализ контента возможен и без разделения на реплики, но наличие диалогов поможет с выделением ненормативной лексики (она часто именно в репликах)."
            ],
            "children": []
          },
          {
            "title": "3. Анализ контента по категориям (классификация нарушений)",
            "level": 3,
            "content": [
              "На этом этапе каждая сцена (или даже каждый фрагмент реплика/описание) проверяется на наличие элементов из целевых категорий: насилие, секс, лексика, наркотики, страх.",
              "Подход 1: правил-based + слова-триггеры. Вручную составляем списки и правила: - Ненормативная лексика: список запрещённых слов (мат). Это однозначно: если в тексте встречается одно из известных мат-слов (даже в составе слова) – отмечаем Profanity=Severe. Можно также добавить список просто грубых слов (не мат, но грубость: «чёрт», «блин», «дерьмо», «сука» в значении животного и т.п.) – их появление отметить как Mild или Moderate profanity, в зависимости от количества. Это легко через поиск по словарю. Здесь нам пригодится учёт морфологии: мат в русском языке имеет множество форм (корень, суффиксы). Можно хранить в виде регулярных выражений или использовать словарь с леммами. Например, spaCy/Natasha лемматизирует и сравнивает с базовой формой. - Наркотики/алкоголь: словарь слов: «водка», «пиво», «наркотик», «героин», «косяк», «сигарета», «курит», «выпивает» и т.п. Если встречается, то Drugs=Moderate (т.к. упоминание). Если в контексте фразы увидим, что пропаганда – это сложно определить автоматически (нужно понять тон), поэтому по умолчанию любое явное изображение употребления алкоголя/наркотика дадим Moderate. Если таких сцен много, итог может стать 16+. Если прямо написано «герой предлагает ребенку наркотик» – можно квалифицировать как Severe (18+), но такие тонкости лучше доверить модели. - Насилие: набор слов: «ударил», «выстрелил», «убил», «кровь», «рана», «кричит от боли», «растерзан», «мёртвый»... Если есть «кровь», «кишки» – сразу Severe (кровавое насилие). Если просто факт драки – Mild/Moderate в зависимости от контекста (драка без последствий vs жестокое избиение). Правилами тяжело детально разделить, тут лучше ML. - Сексуальный контент: слова: «поцелуй», «обнажён», «секс», грубые сексуальные термины. Если «поцеловал» – Mild, если «занимается сексом» – Moderate (16+), если подробное описание акта или порнография – Severe (18+). Опять же, точность требует понимать контекст (например, «он пошёл за ней в спальню – намёк, но без описаний, может пройти как 16+). - Страх и ужасы: слова: «страх», «ужас», «чудовище», «призрак», «убегает в панике», «кричит от ужаса», описания очень мрачные. Если встречаются – отметим Fear=Mild/Moderate. Если присутствует графическое пугающее описание (пересекается с gore) – Severe.",
              "Такой словарно-правильный метод очень быстрый, но может давать много ошибок (ложные, пропуски). Поэтому мы усилим его статистическим/ML методом.",
              "Подход 2: ML-классификаторы или LLM: - Можно обучить модель (например, на основе RuBERT или мультиязычного BERT) классифицировать текст на эти категории. Однако, нужен датасет. В рамках конкурса, вероятно, у участников есть данные (например, размеченные сценарии в дополнительных материалах). Можно обучить 5 отдельных моделей: каждая на свой класс (бинарная с определением тяжести: нет/мягко/сильно). Либо одну многоклассовую с multi-label выходом (несколько категорий сразу). Предпочтительно multi-label, чтоб одна модель обрабатывала текст сцены и выдавала по каждому типу вероятность и/или класс. - Если обучать некогда, можно использовать готовые LLM. Например, взять LLaMA-13B с инструкцией: «Прочитай следующий текст сцены и оцени: есть ли насилие (нет, лёгкое, умеренное, сильное?), есть ли секс (…), …». Модель в принципе способна это сделать, особенно если немного дообучить на примерах. Это упростит разработку (не нужно вручную прописывать все правила), но вызовы модели для каждой сцены 120 раз – может быть долго. Хотя, 13B модель на GPU за 5 минут может успеть 100 коротких запросов. - Оптимально комбинировать: сначала rules отсеяли явно чистые или явно плохие случаи, потом LLM проверила пограничные. - Например, если ни одно ключевое слово не всплыло, LLM можно не звать – сцена считается «None» по всем категориям (с минимальной вероятностью ошибки). Если всплыло, скажем, слово «ударил», вызываем LLM, чтобы она точно классифицировала «это сцена драки, moderate violence». - Также можно определять severity по количеству/контексту: если матерных слов >3 в сцене – Mark profanity Severe (много мата). Если 1 мягкое – Mild. Если 1 мат – Severe сразу. - Используя LLM, желательно сформировать четкий промпт. Например:",
              "Инструкция: Вы контент-аналитик. Классифицируйте следующий фрагмент сценария по категориям:Текст сцены: \"....\"Вывод: Насилие: None/Mild/Moderate/SevereСекс: ...Лексика: ...Наркотики: ...Страх: ...",
              "Такой output, если модель хорошо понимает, будет легко парсить. Можно дать примеры. - Если LLM не слишком надежно выдаёт нужный формат, можно попросить ответить JSON-структурой – некоторые модели умеют. Либо делать несколько запросов (например, 5 отдельных вопросов), но это дольше.",
              "Комбинированная стратегия: 1. Быстрый проход по сценам: для каждой сцены сканируем текст на ключевые слова. 2. Составляем список сцен, требующих детального анализа (где найден хотя бы один триггер). 3. Для каждой из них вызываем ML/LLM-классификатор. Он возвращает категории и severity. 4. Для сцен без триггеров – помечаем все категории None (возможно, с небольшим риском пропустить что-то завуалированное, но экономим время). 5. Собираем результаты.",
              "Учет контекста и связности: - Иногда нарушение может быть расплыто по двум сценам (например, в одной угрозили, в другой выполнили). Но обычно классификация по сценам достаточно независима. - Реплики vs описания: можно анализировать их отдельно, но лучше слить сцену в один блок текста, чтобы модель видела и описание, и диалоги – для контекста. Но при генерации рекомендаций мы все равно сможем сослаться на конкретные строки."
            ],
            "children": []
          },
          {
            "title": "4. Определение возрастного рейтинга",
            "level": 3,
            "content": [
              "После того, как все сцены помечены категориями, определяем финальный возрастной рейтинг сценария: - Инициализируем рейтинг как 0+ (самый мягкий). - Если хотя бы одна сцена имеет категорию со степенью Severe, устанавливаем соответствующий рейтинг 18+. (Severe у нас означает 18+ контент однозначно, например мат, порно, жестокое насилие). - Иначе, если есть хотя бы одна сцена Moderate: тут нужно решить, 16+ или 12+. В системе Parents Guide обычно Moderate тянет на рейтинг PG-13 или 16. По нашему закону: - 12+ допускает эпизодическое насилие без крови, эпизодические упоминания алкоголя без демонстрации, лёгкую лексику. - 16+ допускает то же, но более частое, плюс отдельные несильные бранные слова, более откровенные сцены. - Грубо: если категория = Moderate по насилию или сексу, скорее всего 16+. Если все Moderate только Mild/Moderate, но нет явных 16+ признаков, может быть 12+. Однако, чтобы не недооценить, лучше выбрать 16+ если есть Moderate. - Можно уточнить: если все Moderate относятся к категориям, разрешённым в 12+ (например, одна драка без крови – закон допускает это с 12+), то мы могли бы дать 12+. Но алгоритмически сложно, поэтому можем упростить: наличие любого Moderate => 16+. Это консервативно, но безопасно. В крайнем случае, жюри могут заметить, если неправильно присвоили 16 вместо 12, но это менее критично, чем промахнуться ниже. В рамках баллов за точность рейтинга постараемся всё же поближе к правилам: - Например, одна сцена драки без крови мы хотим оставить 12+, а не 16. Для этого нужно определить, что насилие=Moderate, но с оговоркой «эпизодическое». Мы можем анализировать частоту: если эпизодов насилия 1-2 за фильм, можно 12+. Если их много – 16+. - Сделаем так: если Moderate и количество таких сцен > определённого порога – 16+, иначе, если только 1-2 moderate эпизода – 12+. Аналогично для других категорий: один случай мягкой ругани – можно 12+ (хотя закон говорит вообще никакой бранной лексики до 16 нельзя, так что с лексикой строго: любое есть -> минимум 16). - Возможно, лучше заложить таблицу в конфиг:",
              "if Profanity >= Mild -> rating >= 16 (так как хоть и не мат, но ненормативка)if Violence = Moderate and count >2 -> rating >=16 else 12if Fear = Moderate -> rating >=12 (страшные сцены допустимы с 12)",
              "А, действительно, 12+ уже подразумевает moderate (кроме секса и мата). Так что moderate violence, moderate fear – 12+ (как максимум). 16+ нужно, если присутствует что-то из того, что 12+ не допускает, например, какие-то бранные слова (которые не мат) или более частое. Закон прямо перечисляет: 16+ допускает \"отдельные бранные слова не относящиеся к ненормативной лексике\"[10] – то есть лёгкую брань. 12+ вообще про лексику не упоминает – то есть, наверное, никакой брани. Поэтому: если есть хоть одна ругань (даже \"чёрт\") – делаем 16+. Если есть упоминание наркотиков – закон разрешает редкое упоминание с негативным контекстом в 12+. Но если прям показано или несколько раз – 16+. Мы не достигнем точности эксперта в тонкостях, но постараемся логикой.",
              "Если нет Moderate и Severe, но есть Mild где-то: значит все нарушения минимальны – можно дать 12+ или 6+?",
              "6+ разрешает очень ограниченное: чуть-чуть незапугающе показывать смерть, нет преступлений. 12+ разрешает эпизодическое насилие.",
              "Если у нас Mild насилие (например, сказочная драка) – возможно 6+. Однако, закон 6+ тоже имеет ограничения (не должно быть обнажения, нельзя поощрение плохого и т.п.).",
              "Наверное, если нашли хоть что-то (даже Mild), для перестраховки лучше 6+ или 12+. Но 6+ разрешает уже некоторые вещи.",
              "Например, мультик где чуть-чуть дерутся – обычно 6+.",
              "Тогда: если только Mild нарушения – даём 12+, а если мы уверены, что они short и stylized – можно 6+. Но модель не различит «натуралистичность».",
              "Поэтому, упростим: если нашлись любые нарушения (Mild), но ни одного Moderate – присвоим 12+.",
              "А если вовсе нарушений нет (все категории None) – присвоим 0+.",
              "Это, конечно, грубовато, но учитывая, что большинство сценариев наверняка не G-rated совсем, 0+ будет редким.",
              "Таким образом, алгоритм рейтинга:",
              "rating = \"0+\"if any(issue.severity == \"Severe\"): rating = \"18+\"else if any(issue.severity == \"Moderate\"):     rating = \"16+\"   # (можно уточнить условия для 12+)else if any(issue.severity == \"Mild\"):     rating = \"12+\"   # (дополнительно, если только мелочи, можно 6+, но опустим)else:    rating = \"0+\"",
              "Мы можем немного подстраховаться как выше: если Mild только в категориях, разрешимых в 6+ (скажем, один эпизод упоминания болезни или несмертельная авария) – можно 6+. Но для простоты остановимся на 12+.",
              "Далее, помечаем проблемные сцены: - Если рейтинг оказался, например, 18+, то проблемные – все сцены, где были Severe нарушения (те, что и вызвали 18+). - Если рейтинг 16+, проблемные – сцены с Moderate (или хуже, но хуже не было). - То есть проблемные = сцены содержащие нарушения уровня итогового рейтинга. - Также, возможно, стоит включить сцены на один уровень ниже, если их много, чтобы пользователь видел и их. Но слово \"проблемные\" подразумевает именно те, что существенно влияют на повышение рейтинга. Поэтому остановимся на этом критерии."
            ],
            "children": []
          },
          {
            "title": "5. Формирование аннотаций и рекомендаций",
            "level": 3,
            "content": [
              "Имея список проблемных сцен и данные о нарушениях, генерируем текстовые комментарии: - Для каждой проблемной сцены: - Извлекаем из нее конкретный фрагмент, на котором основана классификация. Например, если метка Violence стоит, можно найти предложение, содержащее слово из словаря насилия, или реплику, где происходит акт. - Проще: когда классифицировали, можно сохранять пояснение: например, rule-based модуль нашёл слово \"убил\" – сохранить: issue.detail = \"упоминание убийства\". LLM классификатор мог бы возвращать небольшой тег (наподобие parent's guide bullet). - Если мы использовали LLM для классификации, можно его же попросить выдать одно предложение описания: «Персонаж ножом ранит другого, показывая кровь». - Впрочем, лучше генерировать отдельно для отчёта, чтобы контроль формата. Можно написать шаблоны: - Насилие: если Severe -> \"Жестокая сцена насилия с кровью/убийством\". - Profanity: \"Нецензурная брань (слово: \"...\")\". - Но шаблонизация всех ситуаций затруднена, поэтому LLM идеально: дать ему текст сцены и сказать \"сформулируй краткое описание нарушения\". - В рамках проекта, можно ограничиться цитированием: например, «Сцена 7: \"... (прямая цитата фразы с матом) ...\" – содержит нецензурную брань.» Это тоже допустимо. - Рекомендация: как описано, либо формируется по правилам (например, если категория Language, рекомендация всегда \"заменить или убрать ненормативную лексику\"; если Violence Severe: \"уменьшить натуралистичность, убрать кровавые подробности\"; если Sex moderate: \"не показывать откровенно, смягчить сцену\"; Drugs: \"не показывать употребление, либо явно осудить его в диалоге\"). Мы можем заранее прописать советы для каждой сочетания категория+severity. - Или доверить LLM: например, подсказать: \"Given that we want to target rating 12+, how to modify this scene?\" – она может ответить советом. Но надо знать, к какому рейтингу стремимся. - Можно спросить LLM в общем: \"Как снизить влияние этого эпизода на рейтинг?\" – ответ: \"Удалить такое-то...\". В принципе, LLM может придумать переписать сцену, но нам скорее нужен лаконичный совет. - Комбинированно: - Если итоговый рейтинг выше желаемого (кстати, часто есть целевой рейтинг, который продюсер выбирает заранее, например, \"хочу снять 12+ фильм\"). Можно в интерфейсе дать выбор \"целевой рейтинг\". Тогда система сравнит: если целевой 12+, а у нас 16+ – все эпизоды, требующие 16+, идут с пометкой \"надо убрать чтобы добиться 12+\". Если целевой не задан, считаем, что хотим минимизировать. - Тут в ТЗ не явно, но первая фраза: \"важно придерживаться выбранного возрастного рейтинга\". То есть предполагается, пользователь знает, какого рейтинга хочет. Можно реализовать: при загрузке сценария спрашивать «Целевой рейтинг: [12+]». - Если так, тогда рекомендации будут разделяться: либо \"для снижения до 12+ сделайте X\", либо если уже соответствует – \"сценарий соответствует выбранному рейтингу, но содержит такие эпизоды которые его обосновывают\". - Мы в проекте отметим эту возможность: выбирать целевой рейтинг.",
              "Использование LLM для рекомендаций: - Выберем небольшую языковую модель (например, 7B) с русским, способную генерировать связный текст. - Можно ее же, что классифицировала, переключить в режим генерации. - Например, промпт:",
              "Сцена: \"...[текст]...\"Обнаружено: Насилие (умеренное) – драка без крови.Сгенерируй совет: как уменьшить рейтинг сцены?",
              "Модель должна выдать что-то вроде: «Убрать подробности драки или сместить акцент, показать последствия вне кадра, чтобы снизить категорию до 12+.» - Если LLM плохо справится, fallback – шаблоны, как сказали.",
              "Совокупная статистика: - После индивидуальных, формируем и общие тексты: - Например, короткий обзор для отчёта: \"В данном сценарии наиболее серьёзное нарушение – ненормативная лексика, поэтому ему присвоен рейтинг 18+. Также присутствуют умеренные сцены насилия и употребления алкоголя.\" - Такой обзор может быть полезен в презентации. Можно сгенерировать LLM на основе всех категорий. - Но обязательно нужно явно указать, к каким нормам это привязано. Может быть, включим в отчёт небольшую справку: \"Согласно ФЗ-436, наличие нецензурной брани автоматически требует категорию 18+.\""
            ],
            "children": []
          },
          {
            "title": "6. Формирование структуры результатов и объектного представления",
            "level": 3,
            "content": [
              "Как упоминалось, после анализа получаем объект AnalysisResult или аналогичный. Он содержит: - Итоговый рейтинг (строка \"0+\", \"6+\" ...). - По каждой категории: максимальная серьезность и статистика (для UI). - Список проблемных эпизодов: каждая запись – сцена, категория, степень, описание, рекомендация. - Опционально: список всех сцен с пометками (для подсветки в интерфейсе).",
              "Этот объект можно сразу же превратить в JSON (например, с помощью Pydantic BaseModel, где поля – финальный рейтинг, словарь категорий, список issues). Этот JSON отправляется фронтенду.",
              "Также этот объект мы сохраняем в базе, как описано ранее, чтобы можно было в будущем достать."
            ],
            "children": []
          },
          {
            "title": "7. Обработка пользовательских корректировок",
            "level": 3,
            "content": [
              "Когда пользователь помечает ложноположительный эпизод: - Backend получает, например, analysis_id, scene_number, category и пометку \"false_positive\". - В базе данных или в памяти (если у нас AnalysisResult сохранён в сессии) мы находим соответствующий issue и помечаем его исключённым. Можно убрать из списка проблемных. - Пересчитываем итоговый рейтинг: возможно, если это был единственный эпизод на уровне 18+, а мы его убрали, теперь рейтинг снизится до следующего. - Например, было 18+ из-за мата, пользователь говорит, что на самом деле слова не было (допустим, OCR ошибся). Тогда пересчитываем: теперь максимальный – скажем, violence moderate -> рейтинг 16+. - Отправляем обновлённый результат фронтенду (можем переслать только изменённые поля: новый рейтинг, убранный эпизод). - Храним где-то, что это исключение – чтобы не потерять. Например, можно в Issue добавить поле ignored = True. - Для добавления нового эпизода (false negative): - Backend получает данные новой issues (сцена, категория, степень, описание текстом). - Добавляет в список issues, пересчитывает рейтинг (вдруг повысился). - Например, сценарий был оценен 12+, пользователь добавил: \"Сцена 3: герой курит сигарету (Drugs Mild)\" – возможно, рейтинг станет 16+ если раньше не было ничего, потому что 12+ позволяет упоминание, хотя курение... спорно. Но возможно мы решим, что даже с этим останется 12. Но если добавили Mat word – точно поднимется. - Опять же, возвращаем обновлённый результат. - Эти правки пока сессии. При экспорте отчёта, конечно, используются уже откорректированные данные. - Можно сохранить эти правки где-то (в базе) как часть анализа, но т.к. история у нас snapshots, достаточно сохранить уже итоговый откорректированный анализ."
            ],
            "children": []
          },
          {
            "title": "8. Повторный анализ после текстовых правок",
            "level": 3,
            "content": [
              "Если пользователь открыл редактор и изменил текст сцены: - Фронтенд отправляет изменённый текст либо всего сценария, либо только изменённой сцены, на сервер. - Чтобы оптимизировать, можно при редактировании хранить mapping старых сцен к новым: если пользователь поправил одно слово, не обязательно перегонять весь текст. Но реализация проще: отправить весь обновлённый сценарий и повторить шаги 1–6. - Сервер принимает текст, снова проводит сегментацию, анализ и т.д. Это ensure свежие результаты по новому тексту. - Поскольку модель уже загружена, второй прогон будет быстрее (не тратим время на инициализацию). - Возвращаем новые результаты фронту, он обновляет интерфейс. - При этом, можно версионировать: сохраняем новый анализ как отдельную запись истории, но можно связать с предыдущим как \"после правок\". История позволит видеть прогресс: был 18+, стал 16+ после замен слов, например. - В отчёте можно упомянуть \"с учётом правок от [дата]\" – но это уже детали.",
              "Таким образом, модуль анализа работает в цикле: получает текст -> выдаёт данные -> при необходимости, по запросу, снова получает текст/корректировки -> обновляет данные."
            ],
            "children": []
          }
        ]
      },
      {
        "title": "Компоненты интерфейса (GUI) и пользовательский опыт",
        "level": 2,
        "content": [
          "Веб-интерфейс разработан так, чтобы даже не технический специалист (сценарист, продюсер) мог интуитивно понять результаты и быстро внести коррективы. Рассмотрим основные экраны и элементы GUI:"
        ],
        "children": [
          {
            "title": "Загрузка сценария",
            "level": 3,
            "content": [
              "При открытии приложения пользователь видит стартовый экран с предложением загрузить файл сценария: - Форма загрузки: кнопка “Выберите файл” или область drag-and-drop для PDF/DOCX. Рядом – подсказка о поддерживаемых форматах и ограничениях (например, «PDF или Word, до 120 стр.»). - Выбор целевого рейтинга: опциональный выпадающий список или переключатели 0+/6+/12+/16+/18+ со справкой («Целевой рейтинг, которого вы хотите придерживаться»). Пользователь может не выбирать (тогда по умолчанию, допустим, 18+ или «нет предпочтения»). - Выбор модели анализа: если предусмотрено (в настройках), можно на этом же экране показать переключатель: «Модель анализа: [Локальная (offline)] / [OpenAI (через API)]». При выборе внешней – поле ввода API ключа (можно заранее сохранённый). Многие пользователи могут не знать про это, тогда оставят локальную. Это скорее для технического пользователя настройка. - Кнопка “Анализировать” – становится активной после выбора файла. Пользователь запускает процесс.",
              "После запуска: - Индикатор прогресса: Отображается состояние анализа. Можно просто показывать анимацию «Analyzing... это может занять до 5 минут». Лучше информативно: прогресс-бар со этапами: 1. Извлечение текста 2. Сегментация на сцены 3. Анализ контента (можно процент просчитывать, если 50 сцен – шаги 1/50, 2/50... либо просто индикатор неопределённого прогресса). 4. Генерация отчёта (подготовка результатов)",
              "Можно обновлять текст статуса: \"Разбивка на сцены...\", \"Анализ сцен 12/50...\", \"Формирование результатов...\". Эти статусы backend может передавать через WebSocket или polling.",
              "Если анализ проходит очень быстро (маленький сценарий), индикатор может и не успеть показаться, или просто мелькнёт. Ничего страшного."
            ],
            "children": []
          },
          {
            "title": "Экран результатов анализа",
            "level": 3,
            "content": [
              "Когда анализ завершён, интерфейс переключается на режим просмотра результатов. Он состоит из нескольких связанных частей:",
              "a. Заголовок и итоговый рейтинг:В верхней части экрана отображается крупно итоговая оценка, например: «Итоговый возрастной рейтинг: 16+». Рядом, возможно, иконка или цветной значок (например, красный значок \"16+\"). Если был выбран целевой рейтинг, можем добавить: \"(Целевой: 12+)\" и подсветить несоответствие, например, красным, если итог выше целевого. Тогда сразу понятен масштаб проблемы.",
              "Под заголовком кратко перечислим причины: например, мелким шрифтом: \"Причины: умеренное насилие, несколько случаев грубой лексики.\" – своего рода один-два предложения summary. Это можно сгенерировать автоматически.",
              "b. Панель суммарной статистики (Categories Overview):Обычно её располагают сбоку или сверху. Например, в правой части экрана карточка «Обзор по категориям»: - Список 5 категорий, напротив каждой – цветовой индикатор и слово (None/Mild/Moderate/Severe), плюс числа. - Например: - Насилие: Moderate (3 сцены, 8%). - Секс: None (0 сцен). - Лексика: Severe (1 сцена, 2%). - Алкоголь/наркотики: Mild (2 сцены, 5%). - Страшные сцены: Mild (1 сцена, 2%). - Можно оформить это в виде таблицы или набора «progress bars» где длина/цвет указывает степень. Но текст понятнее. - Каждый пункт кликабелен: при клике/наведении – либо подсветить соответствующие сцены на таймлайне, либо открыть модальное окно/секцию с подробностями.",
              "c. Хронология сцен (Таймлайн):Основная центральная область – список всех сцен по порядку: - Каждая сцена представлена строкой или блоком: - Номер сцены (или если есть название – заголовок сцены). - Краткое содержание сцены (можно взять первые 5-7 слов описания, например: \"INT. КВАРТИРА – ДЕНЬ. Анна сидит за столом...\"). - Цветовая метка или значок для самой серьёзной категории в этой сцене. Например, кружок: зелёный если нет нарушений, жёлтый/оранжевый/красный если есть. Если нужно, можно несколько значков для разных категорий, но лучше один – самый строгий. - Возможно, иконки категорий: например, 🗡️ если есть насилие, 🍷 если алкоголь, 💬 если мат (текстовое облачко для лексики) и т.п., но это может быть перегруз. Проще по цвету + по клику подробности. - Если пользователь кликает по сцене, внизу или сбоку отображается детальная информация по сцене: - Полный текст сцены (или хотя бы проблемные строки). Можно сделать раскрывающимся: нажал – под строкой сцены развернулся ее текст (с отступами для диалогов). - В тексте можно подсветить найденные места, напр. жёлтым маркером – все слова/фразы, вызвавшие флаг. Например, матерное слово выделено. - Список нарушений в этой сцене: например, «Насилие: персонаж ударяет охранника (Moderate)». Если была одна категория – одно. Несколько – списком. - Кнопки \"False Positive?\" рядом с каждым пунктом – для отметки, что это не нарушение. Или, например, значок глаза/зачёркнутый, при наведении всплывает \"Отметить как неверно определённое\". - Реализация: можно использовать раскладку типа Master-Detail, где слева список сцен, справа панель с содержанием выбранной сцены. Но поскольку у нас ещё категории summary справа, то, возможно, сделаем так: - Слева широкая область – список сцен, при клике на сцену открывается overlay или модальное окно с подробностями (чтобы не менять компоновку). - Либо, если экран широкий (десктоп), то: - Слева – список сцен (мб в 2 колонки: номер и краткий текст). - Справа – панель категорий (как выше). - Ниже (занимая ширину обеих) – секция подробностей: когда не выбрано – может показывать инструкцию типа «Выберите сцену для просмотра деталей». Когда выбрано – текст сцены и нарушения.",
              "d. Секция “Parents Guide” (Детализация по категориям):Альтернативный или дополнительный вид – аналог IMDb Parents Guide: - Это может быть отдельная вкладка или просто секция ниже. Она перечисляет категории и под ними bullet-пойнты эпизодов: - Violence & Gore: - Moderate. Example: \"A fistfight occurs in one scene; one character gets a bloody nose.\" - Another example: \"A dead body is shown briefly without gore.\" - Profanity: - Severe. Example: \"The F-word is used once in a sexual context.\" - и т.д. - В нашем случае, русифицируя: - Насилие: Умеренное. Эпизоды: «В одной сцене герой дерётся с охранником, без тяжёлых травм», «Найдено тело, кровь не показана». - Лексика: Серьёзное. Эпизоды: «Один из персонажей однажды употребляет грубое нецензурное слово (\\\"...\\\")». - ... - Такие списки мы можем сгенерировать на основе issues. По сути, это тот же список problem issues, сгруппированный по категориям. Они частично дублируют \"проблемные сцены\". Отличие: Parents Guide включает все упомянутые эпизоды, даже умеренные. То есть, можно отображать не только проблемные (которые максимальные), но вообще все найденные нарушения. Например, если есть 5 mild, 2 moderate, 1 severe – все можно вывести, чтобы было полное инфо. Это ценная информация для продюсеров. - Таким образом, вероятно, стоит вывести все эпизоды нарушений по категориям, не ограничиваясь проблемными. Просто проблемные – они severe – сами окажутся в списке. - Реализация: Можно под сводкой категорий сделать раскрывающиеся секции: по нажатию на категорию – появляется список описаний эпизодов. - Или сделать вкладки: \"По сценам\" (таймлайн) и \"По категориям\" (гид для родителей). Тогда пользователь может переключаться между видом упорядоченным по порядку фильма или по типам контента. Это хорошее решение UX.",
              "e. Возможности ручной корректировки: - Отметка ложноположительных: Как описано, возле каждого выявленного эпизода (будь то в списке сцен или в списке категорий) – элемент управления. Например, чекбокс \"[ ] Это не нарушение\". При клике – отправляется на сервер, UI может сразу визуально пометить зачёркнутым или убрать этот пункт, обновить рейтинг. - Добавление пропущенного: Два способа: - 1) На уровне сцены: на панели деталей сцены кнопка \"Добавить нарушение\". Пользователь нажимает, выпадает форма: выбрать категорию (выпадающий список), выбрать степень (Mild/Moderate/Severe), поле для описания (необязательно, можно автосгенерировать типа \"пользовательское замечание\"). После заполнения жмёт ОК – этот эпизод добавляется к анализу. На UI сцена получает соответствующую метку. - 2) Прямо выделением текста: более продвинутый вариант – если текст сцены отображается, пользователь выделяет курсором фразу, кликает правой кнопкой (если реализуем контекстное меню) или нажимает кнопку \"Add Issue\", при этом выделенный текст записывается как description, категория выбирается из списка, степень тоже. Это чуть сложнее, но удобнее, т.к. сразу знает, к чему относится. - Добавленные вручную эпизоды можно визуально отличать (например, другим значком или пометкой user-added), чтобы не спутать с авто-выявленными. - После добавления, фронтенд обновляет все: возможно, рейтинг повысился – обновляем заголовок, цветовую схему, проценты. - Все эти правки по возможности не требуют полного перезапуска анализа (модели не вызываются), это просто модификация результатов.",
              "f. Редактирование сценария: - Кнопка \"Редактировать сценарий\" (например, иконка карандаша) обычно вверху, рядом с заголовком или в меню. - По нажатию интерфейс может: - Переключиться на вкладку \"Редактор\", где отображается весь текст сценария или покадрово. - Либо сделать каждую сцену редактируемой: например, превратить текст сцены (в раскрытом детальном виде) в textarea. - Простой вариант: открыть модальное окно с содержимым всего сценария в textarea (промотать трудно). Лучше, наверное, постранично или сцена за сценой. - Можно сделать, например, вместо списка сцен – список сцен с текстовыми полями. Но это перегрузит страницу если 100 сцен. - Может, лучше по одной сцене: пользователь выбирает сцену, нажимает \"редактировать сцену\" – та же панель деталей, но поля можно редактировать (диалоги и описания). Он правит, нажимает \"Сохранить сцену\". - После сохранения конкретной сцены – можем пересчитать только эту сцену: прогнать классификатор на неё новую и обновить ее метки. Но изменения текста могут влиять на соседние сцены? Нет, если мы редактируем внутри сцены. - Если пользователь глобально перестроил сценарий (добавил или удалил сцену, реплики) – тогда лучше пересчитать полностью. - Вероятно, проще: при любом существенном изменении – кнопка \"Перезапустить анализ\". Пусть пользователь после серии правок нажимает одну кнопку, и backend всё пересчитывает. - UI при этом снова покажет индикатор анализа на ~несколько секунд (на обновлённом тексте, скорее быстрее, если небольшие правки). - Результат обновляется.",
              "g. Экспорт отчёта: - На странице результатов кнопка \"Сохранить отчёт\" или выпадающий список: \"Сохранить как PDF / как DOCX\". - При выборе – браузер скачивает файл. - Перед экспортом можем спросить \"включить детальную статистику? включить текст сценария?\" но, скорее всего, всё по умолчанию. - В отчёте, как обсуждалось, будет раздел \"Возрастная классификация сценария\", таблицы, списки, графики. - Можно добавить обложку с названием, авторами (если где взять – например, имя файла, или поле ввода для названия сценария и автора). - Графики: возможно, построим диаграмму (например, горизонтальные полосы: Violence severity meter, Profanity meter). Для реализации – проще всего сгенерировать matplotlib в backend: - Построить столбчатую диаграмму: категории vs количество случаев. - Или круговую: доля сцен с нарушениями vs без. - Вставить картинкой в PDF (ReportLab) и DOCX. - Цветовое оформление отчёта может повторять цвета UI (для наглядности).",
              "h. История анализов: - Кнопка/вкладка \"История\" – открывает список прошлых результатов: - Показывать: дата/время, имя файла, итоговый рейтинг. Возможно, отметка, сколько проблемных сцен. - Можно добавить поле \"версия\" если один и тот же сценарий несколько раз (например, \"Scenario1 v2 (от 14.11.2025)\"). - По клику на запись – либо: - Открывать в этом же интерфейсе (загрузить из БД JSON и отобразить как будто только что проанализировали). По сути, восстановить состояние UI. Это идеал, но много данных хранить. - Или проще – предоставить ссылку сразу на PDF отчёт из той записи. (Но тогда интерактива не будет, только смотреть). - Лучше восстановление, чтобы можно было сравнивать, но для MVP можно и PDF. - Если реализация восстановления сложна, можно хотя бы дать опцию открыть отчет/JSON. - В истории также можно реализовать удаление записей (крестик).",
              "i. Дополнительные элементы: - Настройки: небольшое меню настроек, где можно указать путь к локальной модели (если она не в контейнере), переключить режим модели, поменять язык (вдруг захотят англ. интерфейс). - Справка: раздел, объясняющий возрастные рейтинги, с ссылками на закон. Можно в UI значок «i» (info): при наведении на категорию вывести подсказку, что значит \"Moderate\" или какие критерии 16+. - Цветовая легенда: где-то на экране пояснение цветов. Например, внизу: зеленый кружок – нет нарушений, жёлтый – допустимо для 12+, оранжевый – для 16+, красный – для 18+. Или текстом: \"Цветовая индикация соответствует степени серьезности: None/Mild/Moderate/Severe.\"",
              "Пример сценария использования (UX):1. Пользователь загружает сценарий \"МойФильм.docx\", выбирает целевой рейтинг 12+ и жмёт \"Анализировать\". 2. Через ~1 минуту получает результаты: итоговый рейтинг 16+ (подсвечено красным, т.к. выше желаемого 12+). В обзоре категорий видит: \"Ненормативная лексика: Severe, 1 эпизод\" и \"Насилие: Moderate, 2 эпизода\". 3. Просматривает таймлайн: видит, что сцена 7 помечена красным – кликает её, открывается текст сцены, где выделена реплика с матерным словом. Рядом рекомендация: \"Заменить или удалить данное выражение для снижения рейтинга\". Он соглашается – это явно придётся править в сценарии. 4. Также видит пару оранжевых сцен (насилие): открывает, там описана драка. Рекомендация: \"Снизить натуралистичность драки, убрать подробности\" – но там и так не было крови, просто драка. Понимает, что это не критично, возможно 12+ допускает драку. Тогда он решает, что эти оранжевые можно оставить. 5. Он идёт в редактор, находит сцену 7, удаляет матерное слово, заменяет на нормативный эквивалент. Жмёт \"Перепроверить\". 6. Система быстро анализирует изменения: матерного слова нет, теперь самая высокая категория – насилие Moderate. Итоговый рейтинг падает до 12+ (интерфейс обновляется, заголовок стал зелёным или нормальным). 7. Пользователь доволен: система показывает теперь \"Итоговый рейтинг: 12+ (соответствует целевому)\". 8. Он экспортирует отчёт PDF, чтобы приложить к заявке. В отчёте перечислено, что есть пара сцен насилия, но без кровопролития (умеренно), и указано, что рейтинг 12+ обоснован. 9. В истории сохраняются обе проверки – до правки (16+) и после (12+), на случай, если понадобится вернуться.",
              "Этот сценарий демонстрирует ценность интерактивности и наглядности."
            ],
            "children": []
          }
        ]
      },
      {
        "title": "Расширяемость и развитие системы",
        "level": 2,
        "content": [
          "Заложенные архитектурные решения призваны обеспечить возможности для расширения функционала в будущем без кардинальной переработки:",
          "Новые категории анализа: Если впоследствии потребуется анализировать дополнительные категории (например, дискриминационные высказывания, экстремизм, суицидальные темы – все, что тоже оговаривается законом), добавить их несложно. В чистой архитектуре достаточно внести изменения в модуль классификации (добавить новую метку и логику определения), обновить таблицу правил рейтинга и слегка модифицировать интерфейс (добавить строчку в сводку категорий). Благодаря принципу feature-first, каждая категория может рассматриваться как отдельная подсистема. Можно даже включить/выключить категории через настройки, не влияя на остальные.",
          "Поддержка других языков и рынков: Хотя текущая задача – русский язык и закон РФ, архитектура модели позволяет заменить или дополнить правила для других систем рейтингов (MPAA, PEGI и т.д.). При желании, можно, например, подключить англоязычную модель и анализировать сценарии на английском по американским стандартам. Для этого стоит вынести языковые зависимости (списки слов-триггеров, модели) в конфигурацию/ресурсы. UI тоже можно локализовать через i18n (React имеет библиотеки для этого).",
          "Улучшение моделей: По мере появления более продвинутых локальных LLM, их легко интегрировать – достаточно реализовать новый класс, имплементирующий наш LLMService. Например, если выйдет русская модель, специально обученная на модерации контента (как OpenAI ContentFilter, но локальный) – её можно подключить вместо текущей.",
          "Тонкая настройка на данные пользователя: Сохраненные пометки ложноположительных/ложноотрицательных случаев можно использовать для дообучения моделей (fine-tuning) на конкретный стиль контента. Например, если постоянно модель ошибается, и пользователь исправляет – эти данные накопятся. Можно реализовать модуль обучения, который периодически обновляет классификатор на основе подтверждённых пользователем данных. Это улучшит точность со временем для специфичных сценариев.",
          "Масштабирование на несколько пользователей или облако: Сейчас система однопользовательская и в RAM/VRAM держит одну модель, обрабатывая по очереди. Если возникнет потребность запустить сервис для множества пользователей (например, онлайн-сервис на сервере), можно:",
          "Разделить frontend и backend и развернуть backend с очередью задач. Обработка тяжёлая – GPU – можно сделать пул воркеров Celery, обрабатывающих запросы параллельно, если несколько GPU.",
          "Предусмотреть авторизацию и многопользовательскую БД (привязать записи анализов к пользователям).",
          "Хранение файлов сценариев, возможно, на облаке (S3).",
          "Однако, конкурсная задача фокусируется на функционале, так что это будущие шаги.",
          "Интеграция с редакторскими системами: В перспективе, такой анализ можно интегрировать в ПО для написания сценариев. Архитектура API-ориентированная – позволяет прикрутить, например, плагин к Microsoft Word или Google Docs, который будет дергать наш API при работе со сценарием. Clean Architecture упрощает создание других интерфейсов (например, CLI-утилиты для анализа сценария без веб-интерфейса, или Telegram-бота, куда отправляешь файл – он возвращает результат).",
          "Презентация результатов и бизнес-ценность: Заложенные визуализации (цветовой таймлайн, диаграммы, отчёт) ориентированы не только на технический анализ, но и на представление результатов продюсерам, инвесторам, редакторам. Это повышает бизнес-ценность – результаты понятны и выглядят профессионально. Например, диаграммы можно использовать в презентациях, что оценит жюри (критерий демонстрации).",
          "Дальнейшее улучшение UX: Можно добавить функциональность сравнения версий сценария (до и после правок) – показывать дифф, и как изменился рейтинг. Это потребует хранить версии и инструментов сравнения текста.",
          "Безопасность и права: Если сервис когда-нибудь станет публичным, учтём права на загружаемые сценарии (конфиденциальность). Но в рамках офлайн-решения это на ответственности пользователя.",
          "В целом, предложенная архитектура соответствует принципам высокоуровневого дизайна и позволяет эффективно решать поставленную задачу. Мы выделили доменные сущности и логику (анализ возрастного рейтинга) в самостоятельный модуль, который легко тестировать и совершенствовать. Использование современных подходов к LLM гарантирует актуальность решения: можно применять новейшие модели и методики (квантование, fine-tuning, адаптация с PEFT) для улучшения качества классификации. Благодаря чистой архитектуре с разделением на фичи и слоями, система будет поддерживаемой и масштабируемой в долгосрочной перспективе[9].",
          "Вывод: Данная документация описывает полный цикл работы сервиса – от получения сценария до выдачи отчёта – с пояснением архитектурных и технических решений. Реализация на выбранном стеке (FastAPI + React + локальные LLM) обеспечит соответствие всем критериям: функциональная полнота (точная сегментация, классификация, агрегирование рейтинга), удобство интерфейса (интуитивные визуализации, интерактивность) и возможность автономной работы без внешних API. Проект принесёт реальную пользу киноиндустрии, делая процесс проверки сценариев на соответствие возрастным рейтингам более быстрым, прозрачным и экономичным, что напрямую отвечает заявленной проблеме и требованиям бизнеса.",
          "[1] [10] On Protecting Children from Information Harmful to Their Health and Development - Wikipedia",
          "https://en.wikipedia.org/wiki/On_Protecting_Children_from_Information_Harmful_to_Their_Health_and_Development",
          "[2] IMDb \"Parents' Guide\" information collection - Bruji",
          "https://w.bruji.com/forum/viewtopic.php?t=7136",
          "[3] How much VRAM and how many GPUs to fine-tune a 70B parameter model like LLaMA 3.1 locally? - Models - Hugging Face Forums",
          "https://discuss.huggingface.co/t/how-much-vram-and-how-many-gpus-to-fine-tune-a-70b-parameter-model-like-llama-3-1-locally/150882",
          "[4] [6] [7] [8] [9] Complete Guide to Clean Architecture - GeeksforGeeks",
          "https://www.geeksforgeeks.org/system-design/complete-guide-to-clean-architecture/",
          "[5] Rules for Feature-first | Cursor Directory",
          "https://cursor.directory/rules/feature-first"
        ],
        "children": []
      }
    ]
  }
]