# –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —É–ª—É—á—à–µ–Ω–∏—è RAG —Å–∏—Å—Ç–µ–º—ã

## üìä –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

### –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:

1. **Mock embeddings –≤ `rag.py` (—Å—Ç—Ä–æ–∫–∏ 67, 161)**:
   ```python
   "embedding": [0.1 * i for i in range(384)],  # Mock embedding vector
   ```
   - –ù–µ –Ω–µ—Å—É—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
   - –°–æ–∑–¥–∞—é—Ç –ø—Å–µ–≤–¥–æ-—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å

2. **TF-IDF –≤ `knowledge_base.py`**:
   - –ë–∞–∑–æ–≤—ã–π keyword-based –ø–æ–∏—Å–∫
   - –ù–µ –ø–æ–Ω–∏–º–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫—É —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
   - –ü–ª–æ—Ö–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º

3. **–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö**:
   - –ù–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
   - –ú–µ–¥–ª–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –±–æ–ª—å—à–æ–º—É –∫–æ—Ä–ø—É—Å—É

## üéØ –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è

### Embedding –º–æ–¥–µ–ª–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç):
1. **OpenAI text-embedding-3-large** ‚≠ê **–í–´–ë–†–ê–ù–û**
   - –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
   - 3072 –∏–∑–º–µ—Ä–µ–Ω–∏—è, –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
   - –°—Ç–∞–±–∏–ª—å–Ω–æ–µ API
   - –•–æ—Ä–æ—à–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### Vector Database (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç):
1. **Qdrant** ‚≠ê **–í–´–ë–†–ê–ù–û**
   - –û—Ç–ª–∏—á–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
   - –ü—Ä–æ—Å—Ç–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Python
   - –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
   - Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
   - HTTP API –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã

### –†–µ–∑–µ—Ä–≤–Ω—ã–π —Å—Ç–µ–∫:
- Embedding: `sentence-transformers/all-MiniLM-L6-v2`
- Vector DB: Chroma (python-native, –ø—Ä–æ—Å—Ç–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è)

## üèóÔ∏è –ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### –§–∞–∑–∞ 1: –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (–ù–µ–¥–µ–ª—è 1)

#### 1.1 –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤

**`app/infrastructure/services/embedding_service.py`**:
```python
from openai import OpenAI
from typing import List
import numpy as np

class EmbeddingService:
    def __init__(self):
        self.client = OpenAI()
        self.model = "text-embedding-3-large"
        self.dimension = 3072
    
    async def embed_text(self, text: str) -> List[float]:
        """–°–æ–∑–¥–∞—Ç—å embedding –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        response = self.client.embeddings.create(
            model=self.model,
            input=text,
            encoding_format="float"
        )
        return response.data[0].embedding
    
    async def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """Batch embedding –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤"""
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å batch processing
        pass
```

**`app/infrastructure/services/vector_database_service.py`**:
```python
from qdrant_client import QdrantClient
from qdrant_client.http import models
from typing import List, Dict, Any

class VectorDatabaseService:
    def __init__(self, collection_name="rag_corpus"):
        self.client = QdrantClient(":memory:")  # –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
        self.collection_name = collection_name
        self._ensure_collection()
    
    def _ensure_collection(self):
        """–°–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
        # TODO: –°–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        pass
    
    async def upsert_documents(self, documents: List[Dict[str, Any]]):
        """–î–æ–±–∞–≤–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å upsert —Å embeddings
        pass
    
    async def search(self, query_embedding: List[float], limit: int = 5):
        """–ü–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤—É"""
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
        pass
```

#### 1.2 –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ RAG –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞

**`app/infrastructure/services/rag_orchestrator.py`**:
```python
from app.infrastructure.services.embedding_service import EmbeddingService
from app.infrastructure.services.vector_database_service import VectorDatabaseService

class RAGOrchestrator:
    def __init__(self):
        self.embedding_service = EmbeddingService()
        self.vector_db = VectorDatabaseService()
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π TF-IDF –∫–∞–∫ fallback
        self.tfidf_fallback = KnowledgeBase()
    
    async def add_to_corpus(self, content: str, metadata: Dict[str, Any]):
        """–î–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î"""
        embedding = await self.embedding_service.embed_text(content)
        await self.vector_db.upsert_documents([{
            "content": content,
            "embedding": embedding,
            "metadata": metadata
        }])
    
    async def search(self, query: str, limit: int = 5):
        """–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ —Å fallback"""
        try:
            query_embedding = await self.embedding_service.embed_text(query)
            return await self.vector_db.search(query_embedding, limit)
        except Exception as e:
            # Fallback –∫ TF-IDF –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
            return await self.tfidf_fallback.query(query, limit)
```

#### 1.3 –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

**`.env`**:
```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Qdrant Configuration  
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=script_rating_rag

# Embedding Configuration
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_BATCH_SIZE=100
EMBEDDING_MAX_TOKENS=8191
```

### –§–∞–∑–∞ 2: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º API (–ù–µ–¥–µ–ª—è 1-2)

#### 2.1 –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ RAG routes

**–ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è `app/presentation/api/routes/rag.py`**:

```python
# –ó–∞–º–µ–Ω–∞ mock embeddings –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ
@router.post("/corpus/update")
async def update_corpus(request: CorpusUpdateRequest) -> CorpusUpdateResponse:
    # –°–æ–∑–¥–∞—Ç—å embedding –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    rag_orchestrator = RAGOrchestrator()
    await rag_orchestrator.add_to_corpus(
        content=request.content,
        metadata={
            "category": request.category.value,
            "source_title": request.source_title,
            "source_metadata": request.source_metadata
        }
    )
    
    # –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å content hash
    content_hash = str(hash(request.content))[:16]
    doc_id = str(uuid.uuid4())
    
    return CorpusUpdateResponse(
        update_id=doc_id,
        content_hash=content_hash,
        updated_at=datetime.utcnow()
    )

@router.post("/query")
async def query_rag(request: RAGQueryRequest) -> RAGQueryResponse:
    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
    rag_orchestrator = RAGOrchestrator()
    results = await rag_orchestrator.search(request.query, request.top_k)
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    formatted_results = []
    for result in results:
        formatted_results.append(RAGResult(
            content=result["content"],
            relevance_score=result.get("score", 0.0),
            source=CitationSource(**result["metadata"]["source"]),
            category=Category(result["metadata"]["category"])
        ))
    
    return RAGQueryResponse(
        query=request.query,
        results=formatted_results,
        total_found=len(formatted_results)
    )
```

#### 2.2 Docker –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

**`docker-compose.yml` (–¥–æ–±–∞–≤–∏—Ç—å)**:
```yaml
services:
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334

volumes:
  qdrant_data:
```

### –§–∞–∑–∞ 3: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (–ù–µ–¥–µ–ª—è 2)

#### 3.1 –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ

**`app/infrastructure/services/cache_service.py`**:
```python
from functools import lru_cache
from typing import Dict, Any
import hashlib
import json

class EmbeddingCache:
    def __init__(self, max_size: int = 10000):
        self.cache: Dict[str, List[float]] = {}
        self.max_size = max_size
    
    def _get_cache_key(self, text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á –∫—ç—à–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        return hashlib.md5(text.encode()).hexdigest()
    
    def get(self, text: str) -> List[float] | None:
        """–ü–æ–ª—É—á–∏—Ç—å embedding –∏–∑ –∫—ç—à–∞"""
        return self.cache.get(self._get_cache_key(text))
    
    def set(self, text: str, embedding: List[float]):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å embedding –≤ –∫—ç—à"""
        if len(self.cache) >= self.max_size:
            # –£–¥–∞–ª–∏—Ç—å —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π —ç–ª–µ–º–µ–Ω—Ç
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
        
        self.cache[self._get_cache_key(text)] = embedding
```

#### 3.2 –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –º–µ—Ç—Ä–∏–∫–∏

**`app/infrastructure/services/metrics_service.py`**:
```python
from dataclasses import dataclass
from datetime import datetime
from typing import List

@dataclass
class RAGMetrics:
    query_count: int = 0
    avg_response_time: float = 0.0
    cache_hit_rate: float = 0.0
    embedding_generation_time: float = 0.0
    vector_search_time: float = 0.0

class RAGMetricsService:
    def __init__(self):
        self.metrics = RAGMetrics()
    
    def track_query(self, response_time: float):
        """–û—Ç—Å–ª–µ–¥–∏—Ç—å –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –∑–∞–ø—Ä–æ—Å–∞"""
        self.metrics.query_count += 1
        # –û–±–Ω–æ–≤–∏—Ç—å —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
        self.metrics.avg_response_time = (
            (self.metrics.avg_response_time * (self.metrics.query_count - 1) + response_time) /
            self.metrics.query_count
        )
    
    def get_report(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç—á–µ—Ç –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º"""
        return {
            "total_queries": self.metrics.query_count,
            "avg_response_time_ms": round(self.metrics.avg_response_time * 1000, 2),
            "cache_hit_rate": round(self.metrics.cache_hit_rate * 100, 2),
            "embedding_time_ms": round(self.metrics.embedding_generation_time * 1000, 2),
            "vector_search_time_ms": round(self.metrics.vector_search_time * 1000, 2)
        }
```

### –§–∞–∑–∞ 4: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ (–ù–µ–¥–µ–ª—è 2-3)

#### 4.1 –¢–µ—Å—Ç—ã

**`tests/test_rag_improvements.py`**:
```python
import pytest
import asyncio
from app.infrastructure.services.rag_orchestrator import RAGOrchestrator

class TestRAGImprovements:
    @pytest.fixture
    async def rag_orchestrator(self):
        return RAGOrchestrator()
    
    async def test_embedding_quality(self, rag_orchestrator):
        """–¢–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ embeddings"""
        # –¢–µ—Å—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –±–ª–∏–∑–æ—Å—Ç–∏
        text1 = "–Ω–∞—Å–∏–ª–∏–µ –≤ —Ñ–∏–ª—å–º–∞—Ö"
        text2 = "–∂–µ—Å—Ç–æ–∫–∏–µ —Å—Ü–µ–Ω—ã"
        text3 = "—Ü–≤–µ—Ç–æ–∫ –≤ —Å–∞–¥—É"
        
        embedding1 = await rag_orchestrator.embedding_service.embed_text(text1)
        embedding2 = await rag_orchestrator.embedding_service.embed_text(text2)
        embedding3 = await rag_orchestrator.embedding_service.embed_text(text3)
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ text1 –±–ª–∏–∂–µ –∫ text2 —á–µ–º –∫ text3
        from sklearn.metrics.pairwise import cosine_similarity
        sim_12 = cosine_similarity([embedding1], [embedding2])[0][0]
        sim_13 = cosine_similarity([embedding1], [embedding3])[0][0]
        
        assert sim_12 > sim_13, "Semantic similarity test failed"
    
    async def test_vector_search_performance(self, rag_orchestrator):
        """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        # –î–æ–±–∞–≤–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        test_docs = [
            {"content": "–Ω–∞—Å–∏–ª–∏–µ –≤ —Ñ–∏–ª—å–º–∞—Ö", "metadata": {"category": "violence"}},
            {"content": "—Å–µ–∫—Å—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç", "metadata": {"category": "sexual"}},
            {"content": "–Ω–µ—Ü–µ–Ω–∑—É—Ä–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞", "metadata": {"category": "language"}}
        ]
        
        for doc in test_docs:
            await rag_orchestrator.add_to_corpus(doc["content"], doc["metadata"])
        
        # –¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞
        results = await rag_orchestrator.search("–∂–µ—Å—Ç–æ–∫–∏–µ —Å—Ü–µ–Ω—ã", limit=1)
        assert len(results) > 0
        assert "–Ω–∞—Å–∏–ª–∏–µ" in results[0]["content"]
    
    async def test_fallback_mechanism(self, rag_orchestrator):
        """–¢–µ—Å—Ç fallback –º–µ—Ö–∞–Ω–∏–∑–º–∞"""
        # TODO: –¢–µ—Å—Ç fallback –∫ TF-IDF –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î
        pass
```

#### 4.2 Load —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

**`tests/load/test_rag_load.py`**:
```python
import asyncio
import time
import statistics
from app.infrastructure.services.rag_orchestrator import RAGOrchestrator

async def test_concurrent_searches():
    """–¢–µ—Å—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ RAG —Å–∏—Å—Ç–µ–º–µ"""
    rag_orchestrator = RAGOrchestrator()
    
    queries = [
        "–Ω–∞—Å–∏–ª–∏–µ –≤ —Ñ–∏–ª—å–º–∞—Ö",
        "—Å–µ–∫—Å—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç", 
        "–Ω–µ—Ü–µ–Ω–∑—É—Ä–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞",
        "–≤–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è",
        "–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞"
    ] * 20  # 100 –∑–∞–ø—Ä–æ—Å–æ–≤
    
    start_time = time.time()
    
    async def single_query(query):
        start = time.time()
        await rag_orchestrator.search(query, limit=5)
        return time.time() - start
    
    # –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    tasks = [single_query(query) for query in queries]
    response_times = await asyncio.gather(*tasks)
    
    total_time = time.time() - start_time
    
    print(f"–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ {len(queries)} –∑–∞–ø—Ä–æ—Å–æ–≤: {total_time:.2f}s")
    print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞: {statistics.mean(response_times):.3f}s")
    print(f"–ú–µ–¥–∏–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞: {statistics.median(response_times):.3f}s")
    print(f"95-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å: {statistics.quantiles(response_times, n=20)[18]:.3f}s")
```

## üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–æ–≤—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤:

```
app/infrastructure/services/
‚îú‚îÄ‚îÄ embedding_service.py          # OpenAI embeddings
‚îú‚îÄ‚îÄ vector_database_service.py    # Qdrant –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
‚îú‚îÄ‚îÄ rag_orchestrator.py          # –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä
‚îú‚îÄ‚îÄ cache_service.py             # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ embeddings
‚îî‚îÄ‚îÄ metrics_service.py           # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
```

### API –∏–∑–º–µ–Ω–µ–Ω–∏—è:

1. **–û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å**: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ endpoints
2. **–ù–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏**: –î–æ–±–∞–≤–∏—Ç—å `/rag/stats` —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
3. **–ü—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –º–∏–≥—Ä–∞—Ü–∏—è**: TF-IDF –∫–∞–∫ fallback –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:

```python
# config/rag_config.py
class RAGConfig:
    EMBEDDING_MODEL = "text-embedding-3-large"
    EMBEDDING_BATCH_SIZE = 100
    VECTOR_DB_HOST = "localhost"
    VECTOR_DB_PORT = 6333
    CACHE_SIZE = 10000
    MAX_QUERY_LENGTH = 8191
    DEFAULT_TOP_K = 5
    SIMILARITY_THRESHOLD = 0.7
```

## üöÄ –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

### –≠—Ç–∞–ø 1: MVP (1 –Ω–µ–¥–µ–ª—è)
- –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å OpenAI + Qdrant
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ TF-IDF –∫–∞–∫ fallback
- –ü—Ä–æ—Å—Ç—ã–µ —Ç–µ—Å—Ç—ã

### –≠—Ç–∞–ø 2: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (1 –Ω–µ–¥–µ–ª—è)  
- –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ embeddings
- Batch processing
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –≠—Ç–∞–ø 3: Production (1 –Ω–µ–¥–µ–ª—è)
- Load —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ –ø—Ä–æ–¥–∞–∫—à–Ω
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

## üìä –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –£–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:
- **–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞**: +40-60% (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π vs keyword –ø–æ–∏—Å–∫)
- **–í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞**: +20-30% (–ø—Ä–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–∏)
- **–ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏**: –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ

### –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—Ö–∞:
- –°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: >0.8
- –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ API: <2s –¥–ª—è 95% –∑–∞–ø—Ä–æ—Å–æ–≤
- Cache hit rate: >70%
- Accuracy improvement vs TF-IDF: >50%

## üîÑ Rollback –ø–ª–∞–Ω

–ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ–π–¥–µ—Ç –Ω–µ —Ç–∞–∫:

1. **–û—Ç–∫–ª—é—á–∏—Ç—å –Ω–æ–≤—ã–µ —Å–µ—Ä–≤–∏—Å—ã** —á–µ—Ä–µ–∑ feature flags
2. **–í–µ—Ä–Ω—É—Ç—å—Å—è –∫ TF-IDF** –≤ knowledge_base.py
3. **–û—Ç–∫–ª—é—á–∏—Ç—å Qdrant** –≤ docker-compose.yml
4. **–í–µ—Ä–Ω—É—Ç—å mock embeddings** –≤ rag.py
5. **–û—Ç–∫–∞—Ç–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é** –≤ .env

–í—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –±—É–¥—É—Ç –æ–±—Ä–∞—Ç–∏–º—ã–º–∏ —á–µ—Ä–µ–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–¥–∞.

## üí° –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### –ë—É–¥—É—â–∏–µ —É–ª—É—á—à–µ–Ω–∏—è:
- **Hybrid search**: –ö–æ–º–±–∏–Ω–∞—Ü–∏—è vector + keyword –ø–æ–∏—Å–∫–∞
- **Reranking**: LLM-based reranking —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤  
- **Personalization**: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
- **Multi-modal**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–¥–µ–æ
- **Real-time**: Streaming embeddings –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏:
- **Weaviate**: –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î
- **Chroma**: –õ–æ–∫–∞–ª—å–Ω–∞—è –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î –¥–ª—è –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏
- **Local embeddings**: sentence-transformers –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ API

–≠—Ç–æ—Ç –ø–ª–∞–Ω –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ, –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ RAG —Å–∏—Å—Ç–µ–º—ã —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –±—ã—Å—Ç—Ä–æ–≥–æ rollback –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.